{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e427e448-bb96-4927-9050-978e492d3aef",
   "metadata": {},
   "source": [
    "## Supervised ML on Descartes Labs Platform: Training a Random Forest Classifier\n",
    "__________________\n",
    "This example will demonstrate a typical pattern of training  a supervised classifier using Descartes Labs Platform APIs.\n",
    "\n",
    "The general steps covered in this notebook are:\n",
    "* Retrieve the active [`Function`](https://docs.descarteslabs.com/descarteslabs/compute/readme.html#descarteslabs.compute.Function) created in [02a Generate Training Data.ipynb](02a%20Generate%20Training%20Data.ipynb) and its associated results\n",
    "* Reformat the returned pixel data and train a simple [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* Test inference on a sample tile to visualize land cover predictions \n",
    "* Save the trained model as a [`Blob`](https://docs.descarteslabs.com/descarteslabs/catalog/docs/blob.html#descarteslabs.catalog.Blob) for reference in [02c Deploying a Supervised Classifier.ipynb](02c%20Deploying%20a%20Supervised%20Classifier.ipynb)\n",
    "\n",
    "_**Note:**_ In order to run this example you must first complete the steps outlined in [02a Generate Training Data.ipynb](02a%20Generate%20Training%20Data.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12932b8e-805e-4e7a-ba49-46b94d3ce115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import descarteslabs as dl\n",
    "import descarteslabs.compute\n",
    "import descarteslabs.vector as dl_vector\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely.geometry as sgeom\n",
    "from numpy.typing import NDArray\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e085b5-7d19-4017-ba40-49c445dafbd5",
   "metadata": {},
   "source": [
    "Pulling in the config file, including the NAIP product ID, a list of bands, a start and end date, resolution, and a function name to search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948fd38-4b6c-40fa-a1b8-2decc60eda2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.load(file, yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbddb3-6581-4e0d-af9a-4d47ddbe64a4",
   "metadata": {},
   "source": [
    "## Retrieving an Active Compute Function\n",
    "If you lost your ID, you can retrieve it at [app.descarteslabs.com/compute](https://app.descarteslabs.com/compute) or search the latest created function with that name as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d5224-6af0-4534-9aff-51b811b539ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "func_search = (\n",
    "    dl.compute.Function.search()\n",
    "    .filter(dl.catalog.properties.name == config[\"gen_data_func_name\"])\n",
    "    .sort(-dl.compute.Function.creation_date)\n",
    ").collect()\n",
    "async_func = func_search[0]\n",
    "async_func.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a63f7-3ae5-4372-9de3-131c9f72e905",
   "metadata": {},
   "source": [
    "## Retrieving Function Results\n",
    "\n",
    "Next we will loop through each [`Job`](https://docs.descarteslabs.com/descarteslabs/compute/readme.html#descarteslabs.compute.Job) from our function to access its results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919b7618-3440-45b1-bfb5-1f7f8989f50f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for job in async_func.jobs:\n",
    "    results.append(job.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a83ba-ef89-4864-8ba7-f4d28c78c39b",
   "metadata": {},
   "source": [
    "Since our function from [02a Generate Training Data.ipynb](02a%20Generate%20Training%20Data.ipynb) simply returned a dictionary, we can load each and concatenate as a list of dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a79f05-4182-42aa-a2ad-08aa1777b28c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([gpd.GeoDataFrame(res[\"data\"]) for res in results])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c304042-2c4d-45f4-95f7-304372d2711d",
   "metadata": {},
   "source": [
    "## Reshaping Results for Scikit-Learn\n",
    "\n",
    "In the following cell we'll define a simple function which converts each returned list of band values to numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c109a5e-f71f-4b5c-aeea-c8a955232ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_to_array(row: pd.Series, bands: list[str]) -> NDArray:\n",
    "    val_list = [np.array(y) for y in row[bands].values]\n",
    "    return np.stack(val_list).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246133d1-a399-4047-9ef9-e78140e98ca7",
   "metadata": {},
   "source": [
    "We then group our dataframe by each respective cover type, apply our ndarray conversion function, and concatenate into two training sets that area accepted by [`.fit(X, y)`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4ec47-58d3-4f97-9bba-c221217ea2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "for group, group_df in df.groupby(\"category_int\"):\n",
    "    # Apply the function\n",
    "    X_arrs = group_df.apply(lambda x: list_to_array(x, config[\"bands\"]), axis=1)\n",
    "    X_arr = np.concatenate([x for x in X_arrs])\n",
    "    y_arr = np.full(X_arr.shape[0], group)\n",
    "    X_list.append(X_arr)\n",
    "    y_list.append(y_arr)\n",
    "\n",
    "X = np.concatenate(X_list)\n",
    "y = np.concatenate(y_list)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e425d-3737-4e2a-b9e3-0866ae3d2a6a",
   "metadata": {},
   "source": [
    "Here **X** is shape **(n_samples, n_features)** and **y** is shape **(n_samples, n_outputs)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b45ec-7b84-4c75-aef6-2f2b2415efe3",
   "metadata": {},
   "source": [
    "Now we can perform a simple [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c34a9-d080-4e88-9ea4-ad6ff41611cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3cf306-c2a4-4cc8-a0ad-b9f62c070da3",
   "metadata": {},
   "source": [
    "Declare our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d0819-6507-4337-834f-c22ce714c3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca97f9b-fe3e-4c41-af14-2ea36ed30dae",
   "metadata": {},
   "source": [
    "Fit it on our training samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d212c0-caeb-4ae2-abe0-5fdd7d506669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1ac07-1cd8-4670-b5af-64c94612671c",
   "metadata": {},
   "source": [
    "And evaluate our performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633e195-d3e3-42e7-b0c7-ae1fc14989ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612cbfad-a79a-48c5-9bca-b2c9976d6ecb",
   "metadata": {},
   "source": [
    "## Testing Predictions\n",
    "Now that we've trained the model, we can also see how it performs over test imagery. Here we will define a single tile over which we will see how our model performs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64da0ee7-21de-4203-8789-011c6c256881",
   "metadata": {},
   "source": [
    "Search NAIP over our sample tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd2afc6-e161-4439-b03e-c8b05722ea08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dltile = dl.geo.DLTile.from_latlon(\n",
    "    30.2629, -97.7507, resolution=config[\"resolution_m\"], tilesize=1024, pad=0\n",
    ")\n",
    "naip_ic = (\n",
    "    dl.catalog.Product.get(config[\"product_id\"])\n",
    "    .images()\n",
    "    .intersects(dltile)\n",
    "    .filter(config[\"start\"] <= dl.catalog.properties.acquired < config[\"end\"])\n",
    "    .sort(\"acquired\")\n",
    "    .limit(None)\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c799c-97d8-4079-bd6f-9800050fe276",
   "metadata": {},
   "source": [
    "Retrieve imagery as an ndarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589988fe-e175-497c-b9fa-27256b2caef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndarr = naip_ic.mosaic(\n",
    "    bands=config[\"bands\"],\n",
    "    bands_axis=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51e1f7a-d255-46c0-b55b-6074d049ed64",
   "metadata": {},
   "source": [
    "Reshape to **(n_samples, n_features)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0bf01-c0ad-4415-b7a8-8901321389c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx, ny, nsamples = ndarr.shape\n",
    "in_ras_arr = ndarr.reshape(-1, nsamples)\n",
    "in_ras_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e29b2d-6715-4db4-a3b8-2d42e69efcb0",
   "metadata": {},
   "source": [
    "And predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dfbe41-5ca7-4f3d-926f-b28053d4d452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = clf.predict(in_ras_arr)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10), nrows=1, ncols=2)\n",
    "ax[0].imshow(ndarr)\n",
    "ax[0].set_title(\"FCC\")\n",
    "ax[1].imshow(preds.reshape(nx, ny), cmap=\"terrain\")\n",
    "ax[1].set_title(\"RFC Preds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2685d78f-4ed1-4840-973a-c69f0af19c5e",
   "metadata": {},
   "source": [
    "We may want to outline building shadows next time! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2b0309-c706-4097-b03a-a9bde26291fb",
   "metadata": {},
   "source": [
    "## Saving for Later\n",
    "\n",
    "Once happy with the performance of a model we can save it as a .pickle file and store it as a blob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfdc59a-ada8-4aa6-829d-98465e266687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"training_rfc.pickle\", \"wb\") as rfc_pkl_file:\n",
    "    pickle.dump(clf, rfc_pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e66f27-8f21-48db-bb22-3a87f7fbd08b",
   "metadata": {},
   "source": [
    "#### _Note on Saving Blobs:_\n",
    "We do not always need to delete and overwrite our objects on every iteration as in the following cell. This notebook is designed for demonstration purposes where we do not care about preserving each prior model.\n",
    "\n",
    "In practice, as long as your Blob has a **unique** ID you ignore the following cell and simply run:\n",
    "\n",
    "    blob = Blob(name=\"unique-model-name\")\n",
    "    blob.upload(\"rfc_file.pickle\")\n",
    "    blob.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeefda66-573a-4aa8-a5de-5afc326bacff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blob_name = config[\"trained_model_blob_name\"]\n",
    "\n",
    "try:\n",
    "    # Create a new Blob object\n",
    "    blob = dl.catalog.Blob(\n",
    "        name=blob_name,\n",
    "        tags=[\"examples\"],\n",
    "    )\n",
    "    # Upload our DataFrame to this Blob:\n",
    "    blob.upload(\"training_rfc.pickle\")\n",
    "    blob.save()\n",
    "\n",
    "except dl.exceptions.ConflictError:\n",
    "    print(\"Blob already exists\")\n",
    "    blob = dl.catalog.Blob.get(name=blob_name)\n",
    "    blob.delete()\n",
    "    blob = dl.catalog.Blob(\n",
    "        name=blob_name,\n",
    "        tags=[\"examples\"],\n",
    "    )\n",
    "    # Upload our DataFrame to this Blob:\n",
    "    blob.upload(\"training_rfc.pickle\")\n",
    "    blob.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5025dec-c903-4a7c-a5e4-f55773b9412b",
   "metadata": {},
   "source": [
    "And finally cleaning up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926de483-d991-4ac8-b8b8-2dc1d573a646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.remove(\"training_rfc.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e54616-dbba-4a05-b528-db88aee0e414",
   "metadata": {},
   "source": [
    "Next move on to [02c Deploying a Supervised Classifier.ipynb](02c%20Deploying%20a%20Supervised%20Classifier.ipynb) to scale the inference of the model we just trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a0cab-7626-45aa-89b5-a6b0384e124b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
