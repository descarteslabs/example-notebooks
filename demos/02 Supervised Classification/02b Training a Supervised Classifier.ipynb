{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e427e448-bb96-4927-9050-978e492d3aef",
   "metadata": {},
   "source": [
    "## Supervised ML on Descartes Labs Platform: Training a Random Forest Classifier\n",
    "__________________\n",
    "This example will demonstrate a typical pattern of training  a supervising classifier using Descartes Labs Platform APIs.\n",
    "\n",
    "The general steps covered in this notebook are:\n",
    "* Retrieve a running [`Function`]() and its results\n",
    "* Reformat results for input into a [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "* Save the trained model as a [`Blob`]() for reference in [02c Deploying a Supervised Classifier.ipynb](02c%20Deploying%20a%20Supervised%20Classifier.ipynb)\n",
    "\n",
    "_Note:_ In order to run this example you must first complete the steps outlined in [02a Generate Training Data.ipynb](02a%20Generate%20Training%20Data.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b517618-e154-4e52-8dd5-58568dcd7cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import descarteslabs as dl\n",
    "from descarteslabs.catalog import Blob, Image, Product, properties as p\n",
    "from descarteslabs.compute import Function, Job\n",
    "from descarteslabs.vector import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55a0d9-3bb7-4259-9dc6-9c6957e9f99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, pickle, os\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from shapely.geometry import box\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e085b5-7d19-4017-ba40-49c445dafbd5",
   "metadata": {},
   "source": [
    "Defining global variables for reference throughout this example, including the NAIP product ID, a list of bands, a start and end date, resolution, and a function name to search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf9f68-697f-4547-b3ca-3a7275ba8aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pid = \"usda:naip:v1\"\n",
    "bands = [\"nir\", \"red\", \"green\"]\n",
    "start = \"2020-01-01\"\n",
    "end = \"2021-01-01\"\n",
    "resolution = 1.0  # meters\n",
    "func_name = f\"Get RFC Pixel Values\"\n",
    "func_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71087206-6994-4e6e-9197-04fa024624a5",
   "metadata": {},
   "source": [
    "As well as the current user's namespace information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce032042-7306-46ee-ad78-6c8c1de27fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "org = dl.auth.Auth().payload[\"org\"]\n",
    "user_id = dl.auth.Auth().namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bbddb3-6581-4e0d-af9a-4d47ddbe64a4",
   "metadata": {},
   "source": [
    "## Retrieving an Active Compute Function\n",
    "If you lost your ID, you can retrieve it at [app.descarteslabs.com/compute](https://app.descarteslabs.com/compute) or search the latest created Function with that name as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d5224-6af0-4534-9aff-51b811b539ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "func_search = (\n",
    "    Function.search()\n",
    "    .filter(p.owner == user_id)\n",
    "    .filter(p.name.startswith(\"Get RFC Pixel Values\"))\n",
    "    .sort(-Function.creation_date)\n",
    "    .limit(1)\n",
    ").collect()\n",
    "async_func = func_search[0]\n",
    "async_func.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a63f7-3ae5-4372-9de3-131c9f72e905",
   "metadata": {},
   "source": [
    "## Retrieving Function Results\n",
    "\n",
    "Next we will loop through each [`Job`](https://docs.descarteslabs.com/descarteslabs/compute/readme.html#descarteslabs.compute.Job) from our function to access its results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d72e538-2c26-46b9-b6fa-8aea9b18be76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Results for {async_func.id}\")\n",
    "res_list = []\n",
    "for b in (\n",
    "    Blob.search()\n",
    "    .filter(p.namespace == f\"{org}:{user_id}\")\n",
    "    .filter(p.name.startswith(async_func.id))\n",
    "    .filter(p.storage_type == \"compute\")\n",
    "):\n",
    "    print(f\"ID: {b.id}\")\n",
    "    res_list.append(json.loads(b.data()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a83ba-ef89-4864-8ba7-f4d28c78c39b",
   "metadata": {},
   "source": [
    "Since our function from [02a Generate Training Data.ipynb](02a%20Generate%20Training%20Data.ipynb) simply returned a dictionary, we can load each and concatenate as a list of dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a79f05-4182-42aa-a2ad-08aa1777b28c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([gpd.GeoDataFrame(res[\"data\"]) for res in res_list])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c304042-2c4d-45f4-95f7-304372d2711d",
   "metadata": {},
   "source": [
    "Next up we'll define a simple function which converts each list of band values to numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c109a5e-f71f-4b5c-aeea-c8a955232ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_to_array(x, bands):\n",
    "    val_list = [np.array(y) for y in x[bands].values]\n",
    "    return np.stack(val_list).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b7b2c-ffce-4a1f-8e8b-c592266e71f9",
   "metadata": {},
   "source": [
    "We next group our dataframe by each respective cover type, apply our ndarray conversion function, and concatenate into two training sets that area accepted by [`.fit(X, y)`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit). Where **X** is shape **(n_samples, n_features)** and **y** is shape **(n_samples, n_outputs)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4ec47-58d3-4f97-9bba-c221217ea2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "for group, group_df in df.groupby(\"category_int\"):\n",
    "    X_arrs = group_df.apply(lambda x: list_to_array(x, bands), axis=1)\n",
    "    X_arr = np.concatenate([x for x in X_arrs])\n",
    "    y_arr = np.full(X_arr.shape[0], group)\n",
    "    X_list.append(X_arr)\n",
    "    y_list.append(y_arr)\n",
    "\n",
    "X = np.concatenate(X_list)\n",
    "y = np.concatenate(y_list)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3b45ec-7b84-4c75-aef6-2f2b2415efe3",
   "metadata": {},
   "source": [
    "Now we can perform a simple [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c34a9-d080-4e88-9ea4-ad6ff41611cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3cf306-c2a4-4cc8-a0ad-b9f62c070da3",
   "metadata": {},
   "source": [
    "Declare our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d0819-6507-4337-834f-c22ce714c3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca97f9b-fe3e-4c41-af14-2ea36ed30dae",
   "metadata": {},
   "source": [
    "Fit it on our training samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d212c0-caeb-4ae2-abe0-5fdd7d506669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1ac07-1cd8-4670-b5af-64c94612671c",
   "metadata": {},
   "source": [
    "And evaluate our performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633e195-d3e3-42e7-b0c7-ae1fc14989ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612cbfad-a79a-48c5-9bca-b2c9976d6ecb",
   "metadata": {},
   "source": [
    "## Testing Predictions\n",
    "Now that we've trained the model, we can also see how it performs over test imagery. Here we will define a single tile over which we will see how our model performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4cabde-eacd-4441-9539-58da49cd209e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dltile = dl.geo.DLTile.from_latlon(\n",
    "    30.2629, -97.7507, resolution=resolution, tilesize=1024, pad=0\n",
    ")\n",
    "dltile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64da0ee7-21de-4203-8789-011c6c256881",
   "metadata": {},
   "source": [
    "Search NAIP over our sample tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd2afc6-e161-4439-b03e-c8b05722ea08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naip_ic = (\n",
    "    Product.get(pid)\n",
    "    .images()\n",
    "    .intersects(dltile)\n",
    "    .filter(start <= p.acquired < end)\n",
    "    .sort(\"acquired\")\n",
    "    .limit(None)\n",
    ").collect()\n",
    "naip_ic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c799c-97d8-4079-bd6f-9800050fe276",
   "metadata": {},
   "source": [
    "Retrieve imagery as an ndarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589988fe-e175-497c-b9fa-27256b2caef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndarr = naip_ic.mosaic(\n",
    "    bands=bands,\n",
    "    bands_axis=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51e1f7a-d255-46c0-b55b-6074d049ed64",
   "metadata": {},
   "source": [
    "Reshape to **(n_samples, n_features)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0bf01-c0ad-4415-b7a8-8901321389c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nx, ny, nsamples = ndarr.shape\n",
    "in_ras_arr = ndarr.reshape(-1, nsamples)\n",
    "in_ras_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e29b2d-6715-4db4-a3b8-2d42e69efcb0",
   "metadata": {},
   "source": [
    "And predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dfbe41-5ca7-4f3d-926f-b28053d4d452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = clf.predict(in_ras_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b1998-628c-49e8-aa3b-ba231b0abd0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10), nrows=1, ncols=2)\n",
    "ax[0].imshow(ndarr)\n",
    "ax[0].set_title(\"FCC\")\n",
    "ax[1].imshow(preds.reshape(nx, ny), cmap=\"terrain\")\n",
    "ax[1].set_title(\"RFC Preds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2685d78f-4ed1-4840-973a-c69f0af19c5e",
   "metadata": {},
   "source": [
    "We may want to outline building shadows next time! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2b0309-c706-4097-b03a-a9bde26291fb",
   "metadata": {},
   "source": [
    "## Saving for Later\n",
    "\n",
    "Once happy with the performance of a model we can save it as a .pickle file and store it as a blob:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfdc59a-ada8-4aa6-829d-98465e266687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"training_rfc.pickle\", \"wb\") as rfc_pkl_file:\n",
    "    pickle.dump(clf, rfc_pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e66f27-8f21-48db-bb22-3a87f7fbd08b",
   "metadata": {},
   "source": [
    "#### _Note on Saving Blobs:_\n",
    "We do not always need to delete and overwrite our objects on every iteration as in the following cell. This notebook is designed for demonstration purposes where we do not care about preserving each prior model.\n",
    "\n",
    "In practice, as long as your Blob has a **unique** ID you ignore the following cell and simply run:\n",
    "\n",
    "    blob = Blob(name=\"unique-model-name\")\n",
    "    blob.upload(\"rfc_file.pickle\")\n",
    "    blob.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeefda66-573a-4aa8-a5de-5afc326bacff",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create a new Blob object\n",
    "    blob = Blob(\n",
    "        name=\"training_rfc_model\",\n",
    "        tags=[\"examples\"],\n",
    "    )\n",
    "    # Upload our DataFrame to this Blob:\n",
    "    blob.upload(\"training_rfc.pickle\")\n",
    "    blob.save()\n",
    "\n",
    "except:\n",
    "    print(\"Blob already exists\")\n",
    "    # Already exists within your org\n",
    "    blob = Blob.get(name=\"training_rfc_model\", namespace=f\"{org}:{user_id}\")\n",
    "    blob.delete()\n",
    "    print(\"Deleted blob\")\n",
    "    # Create a new Blob object\n",
    "    blob = Blob(\n",
    "        name=\"training_rfc_model\",\n",
    "        tags=[\"examples\"],\n",
    "    )\n",
    "    # Upload our DataFrame to this Blob:\n",
    "    blob.upload(\"training_rfc.pickle\")\n",
    "    blob.save()\n",
    "blob.save()\n",
    "blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5025dec-c903-4a7c-a5e4-f55773b9412b",
   "metadata": {},
   "source": [
    "And finally cleaning up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926de483-d991-4ac8-b8b8-2dc1d573a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(\"training_rfc.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e54616-dbba-4a05-b528-db88aee0e414",
   "metadata": {},
   "source": [
    "Next move on to [02c Deploying a Supervised Classifier.ipynb](02c%20Deploying%20a%20Supervised%20Classifier.ipynb) to scale the inference of the model we just trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38a0cab-7626-45aa-89b5-a6b0384e124b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
