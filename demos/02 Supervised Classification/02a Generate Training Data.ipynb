{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146c0193-10ec-4aab-82e5-38d6b432dadd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Supervised ML on Descartes Labs Platform: Training a Random Forest Classifier\n",
    "__________________\n",
    "This example will demonstrate a typical pattern of generating training data for a supervised classifier using Descartes Labs Platform APIs.\n",
    "\n",
    "The general steps covered in this notebook are:\n",
    "* Read in a training dataset from [`Vector`](https://docs.descarteslabs.com/api/vector.html) containing simple land cover categories over the Austin, TX area \n",
    "* Visualize our study area and input layers in [`Dynamic Compute`](https://docs.descarteslabs.com/api/dynamic-compute.html)\n",
    "* Split the area into [`DLTile`s](https://docs.descarteslabs.com/descarteslabs/geo/readme.html#descarteslabs.geo.DLTile)\n",
    "* Explore feature masking methodologies\n",
    "* Define an asynchronous [`Function`](https://docs.descarteslabs.com/descarteslabs/compute/readme.html#descarteslabs.compute.Function) which takes a tile key as an input and:\n",
    "    * Searches [`Catalog`](https://docs.descarteslabs.com/descarteslabs/catalog/readme.html) to raster data over the **nir**, **red**, and **green** bands of [National Agricultural Imagery Program (NAIP)](https://app.descarteslabs.com/explorer/datasets/usda:naip:v1) imagery\n",
    "    * Extracts intersecting features as raster masks\n",
    "    * Returns associated pixel values as lists\n",
    "    \n",
    "Move on to [02b Training a Supervised Classifier.ipynb](02b%20Training%20a%20Supervised%20Classifier.ipynb) to retrieve the results of the completed function and train a simple Random Forest Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f9ec79-8d88-4895-b23e-554d94c6f56d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "import descarteslabs as dl\n",
    "import descarteslabs.compute\n",
    "import descarteslabs.vector as dl_vector\n",
    "import descarteslabs.dynamic_compute as dc\n",
    "import geopandas as gpd\n",
    "import ipyleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio.mask\n",
    "import shapely.geometry as sgeom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d994c8-78e6-4e56-9fb1-f0f22396afa3",
   "metadata": {},
   "source": [
    "Load global variables for reference throughout this example, including the NAIP product ID, a list of bands, a start and end date, resolution, and a name for our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e27f3f-dee5-4de7-9b7b-93eec03ce68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.load(file, yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15540a46-269f-4936-97a1-341ef9b27f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "major = sys.version_info.major\n",
    "minor = sys.version_info.minor\n",
    "compute_image = f\"python{major}.{minor}:latest\"\n",
    "compute_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ce091-6dc7-4a44-86ff-deb36992a28f",
   "metadata": {},
   "source": [
    "Next we retrieve a table of sample training features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c4a72-468c-4402-b7fe-67e669ad7420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = dl_vector.Table.get(config[\"training_table_name\"])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce38feb-2e79-4c1c-996a-7c51e555c614",
   "metadata": {},
   "source": [
    "## Study Area - Austin, TX\n",
    "In the next few cells we will set up an interactive map frame to overlay our training feature collection on the input NAIP imagery. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bbf227-f0e5-4ab9-b14f-17a526516a47",
   "metadata": {},
   "source": [
    "Setting up an interactive map, alongside center coordinates and zoom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf6083-6b36-43b0-99f5-fa45f82c6776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = dc.map\n",
    "m.center = 30.2552, -97.7689\n",
    "m.zoom = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a692b029-2e82-4e9b-8e1c-5aefec586470",
   "metadata": {},
   "source": [
    "Create a mosaic of our NAIP imagery and visualize as a false color composite (FCC):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949db953-15b9-4927-84b4-5fda2ce9df7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naip_mosaic = dc.Mosaic.from_product_bands(\n",
    "    config[\"product_id\"],\n",
    "    config[\"bands\"],\n",
    "    start_datetime=config[\"start\"],\n",
    "    end_datetime=config[\"end\"],\n",
    ")\n",
    "naip_mosaic.visualize(\"FCC\", m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3fc94f-2664-47c6-94e2-6be3957730b2",
   "metadata": {},
   "source": [
    "Next visualize our input training table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4913864a-8cf1-4c66-8ca0-a298c4ea08c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table.visualize(\n",
    "    \"Training Polygons\",\n",
    "    m,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b31a14-f764-4e3d-b348-2e9318044216",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generating Training Data - Tiling\n",
    "As outlined above, the general steps to extract training data are as follows:\n",
    "* Splitting up the training AOI into tiles\n",
    "* For each tile we search NAIP imagery and extract all intersecting feature masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bfce8b-cdf2-4414-9430-6918c81996ba",
   "metadata": {},
   "source": [
    "First, lets pull the data from the table and get a feel for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ca432-8381-4659-9961-ed6b21d2f86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = table.collect()\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f968b52-f15c-4fa6-8c5f-ffd791c776fc",
   "metadata": {},
   "source": [
    "We have rows of data with a geometry column, a plain-text category, a category integer (so water maps to the value 3) and a uuid that uniquely identifies each row. Lets look at what the categories are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845825aa-2c77-4407-aac0-6ab2575ebfca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"There are {len(gdf)} features with the following categories: {gdf.category.unique()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcbe73-a82e-48b3-afea-e52edbac01ba",
   "metadata": {},
   "source": [
    "Now we will split our input feature collection into tiles over which we will define our function to iterate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26241f-3376-4cc9-85ab-7b669354d0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf_geom = sgeom.box(*gdf[\"geometry\"].total_bounds)\n",
    "dltiles = dl.geo.DLTile.from_shape(\n",
    "    gdf_geom, resolution=config[\"resolution_m\"], tilesize=2048, pad=0\n",
    ")\n",
    "len(dltiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d092f-12bb-4c42-b180-05d80a436b56",
   "metadata": {},
   "source": [
    "Since our feature collection is sparse and NAIP is high resolution, we want to omit any tiles that don't intersect any of our input features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015989a-aa9f-4bfc-ae48-0b5e6e8cbd9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dltiles = [dltile for dltile in dltiles if gdf.intersects(dltile.geometry).any()]\n",
    "len(dltiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37a9fc-a564-4a0b-a0a5-a404845b5790",
   "metadata": {},
   "source": [
    "Lastly, we can add our tile geometries to the map to visualize our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c61463-fc83-4a72-9ea6-25ac1b64c57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dltile_gdf = gpd.GeoDataFrame(\n",
    "    {\n",
    "        \"geometry\": [dltile.geometry for dltile in dltiles],\n",
    "    },\n",
    "    crs=4326,\n",
    ")\n",
    "geo_data = ipyleaflet.GeoData(\n",
    "    geo_dataframe=dltile_gdf,\n",
    "    style={\"color\": \"grey\", \"fillOpacity\": 0.0},\n",
    "    name=\"DLTiles\",\n",
    ")\n",
    "m.add_layer(geo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044271c-5086-43e3-8d93-d9618c65930f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b8f7f-496f-4501-9e78-8fbf3124829f",
   "metadata": {},
   "source": [
    "## Generating Training Data - Masking\n",
    "\n",
    "Next up we will explore feature masking methodologies. In this example we will retrieve imagery over a sample tile as a geotiff, mask the intersecting features, and return the corresponding band values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa305c9a-4001-418d-85aa-cbbb1f53fd4f",
   "metadata": {},
   "source": [
    "First we will search NAIP over a sample tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233baaa1-7b22-49e7-a0d6-8ccc51944e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dltile = dltiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2171bd-dc1a-4e1a-972d-3c93d064ece8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naip_ic = (\n",
    "    dl.catalog.Product.get(config[\"product_id\"])\n",
    "    .images()\n",
    "    .intersects(dltile)\n",
    "    .filter(config[\"start\"] <= dl.catalog.properties.acquired < config[\"end\"])\n",
    "    .sort(\"acquired\")\n",
    "    .limit(None)\n",
    ").collect()\n",
    "naip_ic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8997b57-9b07-453a-9273-522fc5ac0866",
   "metadata": {},
   "source": [
    "Next we define a function called `generate_polygon_masks`. In this function we will use [`rasterio.mask`](https://rasterio.readthedocs.io/en/latest/api/rasterio.mask.html) to efficienty mask our geotiff downloaded through Catalog to each feature in our training dataset and extract the associated band values into our geodataframe. \n",
    "\n",
    "The function takes 3 arguments:\n",
    "* An input row in a geodataframe\n",
    "* An opened raster dataset\n",
    "* A list of bands for column names\n",
    "\n",
    "It then passes the row's geometry as a feature mask, including **all_touched** to find all pixels that touch our geometry and **crop** to efficiently open a small _window_ of the whole raster. Iterating over each band name, it finally returns a list of corresponding pixel values for each feature (e.g. **nir**, **red**, and **green**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ce2d6-24bd-4c6a-aab4-65d3ae94c530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_polygon_masks(\n",
    "    row: pd.Series, in_dataset: rasterio.io.DatasetWriter, bands: list[str]\n",
    ") -> pd.Series:\n",
    "    \"\"\"Injects for each band the masked pixels for the input geometry in row\"\"\"\n",
    "    # Perform the mask--this returns a feature mask, transform (unused),\n",
    "    # and the window over which to read the input dataset\n",
    "    mask, transform, window = rasterio.mask.raster_geometry_mask(\n",
    "        in_dataset, [row[\"geometry\"]], all_touched=True, crop=True\n",
    "    )\n",
    "    # Opens the input dataset at the specified window\n",
    "    window_arr = in_dataset.read(window=window)\n",
    "    # For each band we mask to the feature and return the stack\n",
    "    # Arr is shape (bands, y, x)\n",
    "    out_arr = np.stack([arr[~mask] for arr in window_arr])\n",
    "    # Figuring out out to best store this--we just return a list of values\n",
    "    # for each band in the input dataset\n",
    "    for idx, band in enumerate(bands):\n",
    "        vals = out_arr[idx].tolist()\n",
    "        row[f\"{band}\"] = vals\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6206f4cb-33ce-4b6b-8e85-925adeac4634",
   "metadata": {},
   "source": [
    "Here we will test things out and plot the steps below:\n",
    "1. Download our NAIP imagery as a geotiff from Catalog\n",
    "2. Open our geotiff in rasterio\n",
    "4. Reproject our geodataframe to local CRS\n",
    "3. Apply our `generate_polygon_masks` function to annotate each feature with contained band values\n",
    "\n",
    "We also will plot out the corresponding windowed masks for the **crop** argument explained above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47502330-2364-42d0-b7df-b67ede8a3fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Downloading mosaic...\")\n",
    "naip_ic.download_mosaic(config[\"bands\"], dest=\"naip_temp.tif\")\n",
    "# Performing the feature sampling by applying the function defined above:\n",
    "with rasterio.open(\"naip_temp.tif\", \"r+\") as in_dataset:\n",
    "    print(\"Performing feature sampling...\")\n",
    "    # Generate Polygon Masks function:\n",
    "    table = dl_vector.Table.get(config[\"training_table_name\"], aoi=dltile)\n",
    "    sampled_gdf = table.collect().to_crs(dltile.crs)\n",
    "    sampled_gdf = sampled_gdf.apply(\n",
    "        lambda row: generate_polygon_masks(row, in_dataset, config[\"bands\"]), axis=1\n",
    "    )\n",
    "    # Visualizing methodology:\n",
    "    # 1. Cropped feature mask:\n",
    "    out_crp_msk, out_crp_trans, out_crp_window = rasterio.mask.raster_geometry_mask(\n",
    "        in_dataset, sampled_gdf.geometry.tolist(), all_touched=True, crop=True\n",
    "    )\n",
    "    # 2. Uncropped feature mask:\n",
    "    out_msk, out_trans, out_window = rasterio.mask.raster_geometry_mask(\n",
    "        in_dataset, sampled_gdf.geometry.tolist(), all_touched=True, crop=False\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 3), nrows=1, ncols=3)\n",
    "    arr = in_dataset.read()\n",
    "    ax[0].imshow(arr.transpose((1, 2, 0))[:, :, :3])\n",
    "    ax[0].set_title(r\"FCC\")\n",
    "    ax[1].imshow(out_msk)\n",
    "    ax[1].set_title(r\"Uncropped Mask\")\n",
    "    ax[2].imshow(out_crp_msk)\n",
    "    ax[2].set_title(r\"Cropped Mask\")\n",
    "plt.tight_layout()\n",
    "os.remove(\"naip_temp.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb6007-b4c2-4bfe-b389-c2c1d8c7a9cc",
   "metadata": {},
   "source": [
    "And here we see the new columns on our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7c1b8-d4dc-426c-b8db-50296564277d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eaaa64-584d-43a0-b74b-87fcca023191",
   "metadata": {},
   "source": [
    "## Putting it All Together with Batch Compute\n",
    "Here we'll define a function which wraps all of the previously outlined methodology into a self-contained Python function. The inputs here are a single tile key and the overall steps are as follows:\n",
    "* Re-create a tile from the passed key\n",
    "* Retrieve the training features clipped to the input tile\n",
    "* Search NAIP over the input tile and retrieve the imagery as a geotiff\n",
    "* Perform the feature sampling method outlined above against the clipped features\n",
    "* Return the associated intersecting band values as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8d9d3-5021-45fa-b124-a982b3cb266c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pixel_values(dltile_key: str):\n",
    "\n",
    "    import json\n",
    "    import os\n",
    "\n",
    "    import descarteslabs as dl\n",
    "    import descarteslabs.vector as dl_vector\n",
    "    import geopandas as gpd\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import rasterio\n",
    "    import rasterio.mask\n",
    "\n",
    "    def generate_polygon_masks(\n",
    "        row: pd.Series, in_dataset: rasterio.io.DatasetWriter, bands: list[str]\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"Injects for each band the masked pixels for the input geometry in row\"\"\"\n",
    "        mask, transform, window = rasterio.mask.raster_geometry_mask(\n",
    "            in_dataset, [row[\"geometry\"]], all_touched=True, crop=True\n",
    "        )\n",
    "        window_arr = in_dataset.read(window=window)\n",
    "        out_arr = np.stack([arr[~mask] for arr in window_arr])\n",
    "        for idx, band in enumerate(bands):\n",
    "            vals = out_arr[idx].tolist()\n",
    "            row[f\"{band}\"] = vals\n",
    "\n",
    "        return row\n",
    "\n",
    "    dltile = dl.geo.DLTile.from_key(dltile_key)\n",
    "    print(f\"Processing {dltile_key}\")\n",
    "\n",
    "    TABLE_ID = \"descarteslabs:austin-landcover-training-data\"\n",
    "    PRODUCT_ID = \"usda:naip:v1\"\n",
    "    START = \"2020-01-01\"\n",
    "    END = \"2021-01-01\"\n",
    "    BANDS = [\"nir\", \"red\", \"green\"]\n",
    "    # Pulling GDF from Vector\n",
    "\n",
    "    table = dl_vector.Table.get(TABLE_ID, aoi=dltile)\n",
    "    gdf = table.collect().to_crs(dltile.crs)\n",
    "\n",
    "    if len(gdf) == 0:\n",
    "        return {}\n",
    "\n",
    "    print(\"Searching Images...\")\n",
    "    naip_ic = (\n",
    "        dl.catalog.Product.get(PRODUCT_ID)\n",
    "        .images()\n",
    "        .intersects(dltile)\n",
    "        .filter(START <= dl.catalog.properties.acquired < END)\n",
    "        .sort(\"acquired\")\n",
    "        .limit(None)\n",
    "    ).collect()\n",
    "    print(naip_ic)\n",
    "\n",
    "    print(\"Downloaded GDF...\")\n",
    "    naip_ic.download_mosaic(\n",
    "        bands=BANDS,\n",
    "        geocontext=dltile,\n",
    "        dest=f\"naip_temp.tif\",\n",
    "        format=\"tif\",\n",
    "    )\n",
    "    print(\"Downloaded GeoTIFF...\")\n",
    "\n",
    "    # Opening the geotiff via Rasterio\n",
    "    with rasterio.open(f\"naip_temp.tif\", \"r+\") as in_ds:\n",
    "        print(\"Performing feature sampling...\")\n",
    "        # Generate Polygon Masks function:\n",
    "        sampled_gdf = gdf.apply(\n",
    "            lambda row: generate_polygon_masks(row, in_ds, BANDS), axis=1\n",
    "        )\n",
    "\n",
    "    # Returning GDF as a dictionary, dropping geom column along the way:\n",
    "    out_data = sampled_gdf.drop(columns=[\"geometry\"]).to_dict()\n",
    "\n",
    "    print(\"Cleaning up\")\n",
    "    # Deleting the tiff from memory\n",
    "    os.remove(f\"naip_temp.tif\")\n",
    "    print(\"Complete\")\n",
    "\n",
    "    return {\"dltile\": dltile_key, \"data\": out_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526c93d-9516-4300-b2ac-15a814d70256",
   "metadata": {},
   "source": [
    "Now that it's all packaged up into a function, we can test it locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f73dd3-7170-4df9-9ebc-5e1de12abdcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(get_pixel_values(dltiles[0].key)[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06641fbc-6c34-460a-8cf5-9362d0f6d3ea",
   "metadata": {},
   "source": [
    "Now we format our input arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65a3d2-1704-4231-9129-2a8169ab1ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = [[dltile.key] for dltile in dltiles]\n",
    "len(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b672fc-bf86-417e-979d-7d5c49e710ec",
   "metadata": {},
   "source": [
    "Once we are happy with the performance of our function we can save it to our Compute service.\n",
    "\n",
    "Note here that we must pass geopandas as a requirement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3cd19a-840d-49a6-b759-5c9f7045eae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async_func = dl.compute.Function(\n",
    "    get_pixel_values,\n",
    "    name=config[\"gen_data_func_name\"],\n",
    "    image=compute_image,\n",
    "    cpus=1,\n",
    "    memory=2,\n",
    "    timeout=300,\n",
    "    maximum_concurrency=20,\n",
    "    retry_count=1,\n",
    ")\n",
    "\n",
    "async_func.save()\n",
    "print(f\"Saved {async_func.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b7e77-92b1-4986-b357-bad826de7e9c",
   "metadata": {},
   "source": [
    "**_Take note of your Function ID!_**\n",
    "\n",
    "And finally map args to our Function to return a set of jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d6d76-21c6-4783-918c-a6dd7f2f7334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobs = async_func.map(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed64a26e-4def-4781-bf5a-45e18d5c0231",
   "metadata": {
    "tags": []
   },
   "source": [
    "Navigate to [app.descarteslabs.com/compute](https://app.descarteslabs.com/compute) to track your progress.\n",
    "\n",
    "Or wait programmatically via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5238dc-0c8a-47c6-b354-9640dc372d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async_func.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5245a4-b5f4-4dcb-8597-757bd4be7f7f",
   "metadata": {},
   "source": [
    "Once this function completes, you can move on to [02b Training a Supervised Classifier.ipynb](02b%20Training%20a%20Supervised%20Classifier.ipynb) to retrieve the results and train our model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a86579-a93d-4f05-9760-9de283b04a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
