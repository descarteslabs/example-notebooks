{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146c0193-10ec-4aab-82e5-38d6b432dadd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Supervised ML on Descartes Labs Platform: Training a Random Forest Classifier\n",
    "__________________\n",
    "This example will demonstrate a typical pattern of generating training data for a supervising classifier using Descartes Labs Platform APIs.\n",
    "\n",
    "The general steps covered in this notebook are:\n",
    "* Read in a training dataset from [`Vector`](https://docs.descarteslabs.com/api/vector.html) containing simple land cover categories over the Austin, TX area \n",
    "* Visualize our study area and input layers in [`Dynamic Compute`](https://docs.descarteslabs.com/api/dynamic-compute.html)\n",
    "* Split the area into [`DLTile`s](https://docs.descarteslabs.com/descarteslabs/geo/readme.html#descarteslabs.geo.DLTile)\n",
    "* Explore feature masking methodologies\n",
    "* Define an asynchronous [`Function`](https://docs.descarteslabs.com/descarteslabs/compute/readme.html#descarteslabs.compute.Function) which takes a tile key as an input and:\n",
    "    * Searches [`Catalog`](https://docs.descarteslabs.com/descarteslabs/catalog/readme.html) to raster data over the **nir**, **red**, and **green** bands of [National Agricultural Imagery Program (NAIP)](https://app.descarteslabs.com/explorer/datasets/usda:naip:v1) imagery\n",
    "    * Extracts intersecting features as raster masks\n",
    "    * Returns associated pixel values as lists\n",
    "    \n",
    "Move on to [02b Training a Supervised Classifier.ipynb](02b%20Training%20a%20Supervised%20Classifier.ipynb) to retrieve the results of the completed function and train a simple Random Forest Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f502e14-5daf-4a7c-92bb-0d2d02f344a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import descarteslabs as dl\n",
    "import descarteslabs.dynamic_compute as dc\n",
    "from descarteslabs.catalog import Blob, Image, Product, properties as p\n",
    "from descarteslabs.compute import Function, Job\n",
    "from descarteslabs.vector import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7107c4-7bf7-422d-abd8-60557eb644b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from ipyleaflet import GeoData\n",
    "from rasterio.mask import raster_geometry_mask\n",
    "from shapely.geometry import box\n",
    "\n",
    "import json, os, pickle, rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d994c8-78e6-4e56-9fb1-f0f22396afa3",
   "metadata": {},
   "source": [
    "Defining global variables for reference throughout this example, including the NAIP product ID, a list of bands, a start and end date, resolution, and a name for our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed3a3d-ead3-465f-9936-e8eb60ded219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pid = \"usda:naip:v1\"\n",
    "bands = [\"nir\", \"red\", \"green\"]\n",
    "start = \"2020-01-01\"\n",
    "end = \"2021-01-01\"\n",
    "resolution = 1.0  # meters\n",
    "func_name = f\"Get RFC Pixel Values {datetime.today().strftime('%Y-%m-%d')}\"\n",
    "func_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ce091-6dc7-4a44-86ff-deb36992a28f",
   "metadata": {},
   "source": [
    "Next we retrieve a table of sample training features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c4a72-468c-4402-b7fe-67e669ad7420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_id = \"descarteslabs:austin-landcover-training-data\"\n",
    "table = Table.get(table_id)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce38feb-2e79-4c1c-996a-7c51e555c614",
   "metadata": {},
   "source": [
    "## Study Area - Austin, TX\n",
    "In the next few cells we will set up an interactive map frame to overlay our training feature collection on the input NAIP imagery. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bbf227-f0e5-4ab9-b14f-17a526516a47",
   "metadata": {},
   "source": [
    "Setting up an interactive map, alongside center coordinates and zoom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf6083-6b36-43b0-99f5-fa45f82c6776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = dc.map\n",
    "m.center = 30.25, -97.74\n",
    "m.zoom = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a692b029-2e82-4e9b-8e1c-5aefec586470",
   "metadata": {},
   "source": [
    "Create a mosaic of our NAIP imagery and visualize as a false color composite (FCC):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949db953-15b9-4927-84b4-5fda2ce9df7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naip_mosaic = dc.Mosaic.from_product_bands(\n",
    "    pid, bands, start_datetime=start, end_datetime=end\n",
    ")\n",
    "naip_mosaic.visualize(\"FCC\", m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3fc94f-2664-47c6-94e2-6be3957730b2",
   "metadata": {},
   "source": [
    "Next visualize our input training table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4913864a-8cf1-4c66-8ca0-a298c4ea08c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table.visualize(\n",
    "    \"Training Polygons\",\n",
    "    m,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b31a14-f764-4e3d-b348-2e9318044216",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generating Training Data - Tiling\n",
    "As outlined above, the general steps to extract training data are as follows:\n",
    "* Splitting up the training AOI into `DLTile`s\n",
    "* For each `DLTile` we search **NAIP** imagery and use `rasterio` to extract all intersecting feature masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611f1e0-e475-45bf-a116-2015d862af1b",
   "metadata": {},
   "source": [
    "First we will split our input feature collection's extent into tiles, over which we will define our funtion to iterate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26241f-3376-4cc9-85ab-7b669354d0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = table.collect()\n",
    "gdf_geom = box(*gdf[\"geometry\"].total_bounds)\n",
    "dltiles = dl.geo.DLTile.from_shape(\n",
    "    gdf_geom, resolution=resolution, tilesize=2048, pad=0\n",
    ")\n",
    "len(dltiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d092f-12bb-4c42-b180-05d80a436b56",
   "metadata": {},
   "source": [
    "Since our feature collection is sparse, and NAIP is high resolution, we want to omit any tiles that don't intersect any of our input features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015989a-aa9f-4bfc-ae48-0b5e6e8cbd9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dltiles = [dltile for dltile in dltiles if gdf.intersects(dltile.geometry).any()]\n",
    "len(dltiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37a9fc-a564-4a0b-a0a5-a404845b5790",
   "metadata": {},
   "source": [
    "Lastly, we can add our tile geometries to the map to visualize our project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c61463-fc83-4a72-9ea6-25ac1b64c57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dltile_gdf = gpd.GeoDataFrame(\n",
    "    {\n",
    "        \"geometry\": [dltile.geometry for dltile in dltiles],\n",
    "    },\n",
    "    crs=4326,\n",
    ")\n",
    "geo_data = GeoData(\n",
    "    geo_dataframe=dltile_gdf,\n",
    "    style={\"color\": \"black\", \"fillOpacity\": 0.0},\n",
    "    name=\"DLTiles\",\n",
    ")\n",
    "m.add_layer(geo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044271c-5086-43e3-8d93-d9618c65930f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b8f7f-496f-4501-9e78-8fbf3124829f",
   "metadata": {},
   "source": [
    "## Generating Training Data - Masking\n",
    "\n",
    "Next up we will explore feature masking methodologies. In this example we will retrieve Catalog imagery over a sample tile as a geotiff and use [rasterio](https://rasterio.readthedocs.io/en/stable/) to efficiently mask our features in a [pd.apply()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa305c9a-4001-418d-85aa-cbbb1f53fd4f",
   "metadata": {},
   "source": [
    "First we will search NAIP over a sample tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233baaa1-7b22-49e7-a0d6-8ccc51944e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dltile = dltiles[0]\n",
    "dltile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2171bd-dc1a-4e1a-972d-3c93d064ece8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naip_ic = (\n",
    "    Product.get(pid)\n",
    "    .images()\n",
    "    .intersects(dltile)\n",
    "    .filter(start <= p.acquired < end)\n",
    "    .sort(\"acquired\")\n",
    "    .limit(None)\n",
    ").collect()\n",
    "naip_ic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8997b57-9b07-453a-9273-522fc5ac0866",
   "metadata": {},
   "source": [
    "Next we define a `generate_polygon_masks` function. We will use [`rasterio.mask`](https://rasterio.readthedocs.io/en/latest/api/rasterio.mask.html) to efficienty mask our geotiff downloaded through Catalog to each feature in our training dataset and extract the associated band values into our geodataframe. \n",
    "\n",
    "This function takes 3 arguments:\n",
    "* An input row in a geodataframe\n",
    "* An opened raster dataset\n",
    "* A list of bands for column names\n",
    "\n",
    "It then passes the row's geometry as a feature mask, including **all_touched** to find all pixels that touch our geometry and **crop** to efficiently open a small _window_ of the whole raster. Iterating over each band name, it finally returns a list of corresponding pixel values for each feature (e.g. **nir**, **red**, and **green**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ce2d6-24bd-4c6a-aab4-65d3ae94c530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_polygon_masks(x, in_ds, bands):\n",
    "    \"\"\"\n",
    "    Takes input row of a geodataframe with a geometry in the same projection as\n",
    "    an input dataset. Performs a raster_geometry_mask and populates the row\n",
    "    with n corresponding unmasked values, one for each band. Also saves the feature's\n",
    "    mask and window for more effecient reading of the geotiff.\n",
    "    \"\"\"\n",
    "    # Perform the mask--this returns a feature mask, transform (unused),\n",
    "    # and the window over which to read the input dataset\n",
    "\n",
    "    out_msk, out_trans, out_wind = raster_geometry_mask(\n",
    "        in_ds, [x[\"geometry\"]], all_touched=True, crop=True\n",
    "    )\n",
    "    x[\"out_msk\"] = out_msk\n",
    "    x[\"out_wind\"] = out_wind\n",
    "\n",
    "    # Opens the input dataset at the specified window\n",
    "    in_window = in_ds.read(window=out_wind)\n",
    "    # For each band we mask to the feature and return the stack\n",
    "    # Arr is shape (bands, y, x)\n",
    "    out_arr = np.stack([a[~out_msk] for a in in_window])\n",
    "    # Figuring out out to best store this--we just return a list of values\n",
    "    # for each band in the input dataset\n",
    "    for i, band in enumerate(bands):\n",
    "        vals = out_arr[i].tolist()\n",
    "        x[f\"{band}\"] = vals\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6206f4cb-33ce-4b6b-8e85-925adeac4634",
   "metadata": {},
   "source": [
    "Here we will test things out and plot the steps below:\n",
    "1. Download our NAIP imagery as a geotiff from Catalog\n",
    "2. Open our geotiff in rasterio\n",
    "4. Reproject our geodataframe to local CRS\n",
    "3. Apply our `generate_polygon_masks` function to annotate each feature with contained band values\n",
    "\n",
    "We also will plot out the corresponding windowed masks for the **crop** argument explained above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47502330-2364-42d0-b7df-b67ede8a3fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Downloading mosaic...\")\n",
    "naip_ic.download_mosaic(bands, dest=\"naip_temp.tif\")\n",
    "# Performing the feature sampling by applying the function defined above:\n",
    "with rasterio.open(\"naip_temp.tif\", \"r+\") as in_ds:\n",
    "    print(\"Performing feature sampling...\")\n",
    "    # Generate Polygon Masks function:\n",
    "    sampled_gdf = gdf.clip(dltile.geometry).to_crs(dltile.crs)\n",
    "    sampled_gdf = sampled_gdf.apply(\n",
    "        lambda x: generate_polygon_masks(x, in_ds, bands), axis=1\n",
    "    )\n",
    "    # Visualizing methodology:\n",
    "    # 1. Cropped feature mask:\n",
    "    out_crp_msk, out_crp_trans, out_crp_window = raster_geometry_mask(\n",
    "        in_ds, sampled_gdf.geometry.tolist(), all_touched=True, crop=True\n",
    "    )\n",
    "    # 2. Uncropped feature mask:\n",
    "    out_msk, out_trans, out_window = raster_geometry_mask(\n",
    "        in_ds, sampled_gdf.geometry.tolist(), all_touched=True, crop=False\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 3), nrows=1, ncols=3)\n",
    "    arr = in_ds.read()\n",
    "    ax[0].imshow(arr.transpose((1, 2, 0))[:, :, :3])\n",
    "    ax[0].set_title(r\"FCC\")\n",
    "    ax[1].imshow(out_msk)\n",
    "    ax[1].set_title(r\"Uncropped Mask\")\n",
    "    ax[2].imshow(out_crp_msk)\n",
    "    ax[2].set_title(r\"Cropped Mask\")\n",
    "plt.tight_layout()\n",
    "os.remove(\"naip_temp.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadb6007-b4c2-4bfe-b389-c2c1d8c7a9cc",
   "metadata": {},
   "source": [
    "And here we see the new columns on our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7c1b8-d4dc-426c-b8db-50296564277d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eaaa64-584d-43a0-b74b-87fcca023191",
   "metadata": {},
   "source": [
    "## Wrapping it All Together with Batch Compute\n",
    "Here we'll define a function which wraps all of the previously outlined methodology into a self-contained Python function. The inputs here are a single tile key and the overall steps are as follows:\n",
    "* Re-create a tile from the passed key\n",
    "* Retrieve the training features clipped to the input tile\n",
    "* Search NAIP over the input tile and retrieve the imagery as a geotiff\n",
    "* Perform the feature sampling method outlined above against the clipped features\n",
    "* Return the associated intersecting band values as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8d9d3-5021-45fa-b124-a982b3cb266c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pixel_values(dltile_key):\n",
    "    import descarteslabs as dl\n",
    "    from descarteslabs.catalog import Blob, Image, Product, properties as p\n",
    "    from descarteslabs.vector import Table\n",
    "\n",
    "    import numpy as np\n",
    "    import geopandas as gpd\n",
    "    from rasterio.mask import raster_geometry_mask\n",
    "\n",
    "    import rasterio\n",
    "    import os\n",
    "    from json import loads\n",
    "\n",
    "    def generate_polygon_masks(x, in_ds, bands):\n",
    "        \"\"\"\n",
    "        Takes input row of a dataframe with a geometry in the same projection as\n",
    "        an input dataset. Performs a raster_geometry_mask and populates the row\n",
    "        with n corresponding unmasked values, one for each band.\n",
    "        \"\"\"\n",
    "        # Perform the mask--this returns a feature mask, transform (unused),\n",
    "        # and the window over which to read the input dataset\n",
    "\n",
    "        out_msk, out_trans, out_wind = raster_geometry_mask(\n",
    "            in_ds, [x[\"geometry\"]], all_touched=True, crop=True\n",
    "        )\n",
    "\n",
    "        x[\"out_msk\"] = out_msk\n",
    "        x[\"out_wind\"] = out_wind\n",
    "\n",
    "        # Opens the input dataset at the specified window\n",
    "        in_window = in_ds.read(window=out_wind)\n",
    "        # For each band we mask to the feature and return the stack\n",
    "        # Arr is shape (bands, y, x)\n",
    "        out_arr = np.stack([a[~out_msk] for a in in_window])\n",
    "        # Figuring out out to best store this--we just return a list of values\n",
    "        # for each band in the input dataset\n",
    "        for i, band in enumerate(bands):\n",
    "            vals = out_arr[i].tolist()\n",
    "            x[f\"{band}\"] = vals\n",
    "        return x\n",
    "\n",
    "    dltile = dl.geo.DLTile.from_key(dltile_key)\n",
    "    print(f\"Processing {dltile_key}\")\n",
    "\n",
    "    table_id = \"descarteslabs:austin-landcover-training-data\"\n",
    "    pid = \"usda:naip:v1\"\n",
    "    start = \"2020-01-01\"\n",
    "    end = \"2021-01-01\"\n",
    "    bands = [\"nir\", \"red\", \"green\"]\n",
    "    # Pulling GDF from Vector\n",
    "\n",
    "    table = Table.get(table_id, aoi=dltile)\n",
    "    gdf = table.collect().to_crs(dltile.crs)\n",
    "\n",
    "    print(\"Downloaded GDF...\")\n",
    "\n",
    "    # This checks whether there are any intersecting features in this Scene, if not\n",
    "    # then we end the Job here.\n",
    "    try:\n",
    "        assert len(gdf) > 0, print(f\"No intersections {dltile_key}\")\n",
    "    except AssertionError:\n",
    "        return {}\n",
    "    print(\"Searching Images...\")\n",
    "\n",
    "    naip_ic = (\n",
    "        Product.get(pid)\n",
    "        .images()\n",
    "        .intersects(dltile)\n",
    "        .filter(start <= p.acquired < end)\n",
    "        .sort(\"acquired\")\n",
    "        .limit(None)\n",
    "    ).collect()\n",
    "    print(naip_ic)\n",
    "\n",
    "    naip_ic.download_mosaic(\n",
    "        bands=bands,\n",
    "        geocontext=dltile,\n",
    "        dest=f\"naip_temp.tif\",\n",
    "        format=\"tif\",\n",
    "    )\n",
    "    print(\"Downloaded GeoTIFF...\")\n",
    "\n",
    "    # Opening the geotiff via Rasterio\n",
    "    with rasterio.open(f\"naip_temp.tif\", \"r+\") as in_ds:\n",
    "        print(\"Performing feature sampling...\")\n",
    "        # Generate Polygon Masks function:\n",
    "        sampled_gdf = gdf.apply(\n",
    "            lambda x: generate_polygon_masks(x, in_ds, bands), axis=1\n",
    "        )\n",
    "\n",
    "    # Returning GDF as a dictionary, dropping geom and index columns along the way:\n",
    "    out_data = sampled_gdf.drop(columns=[\"geometry\", \"out_msk\", \"out_wind\"]).to_dict()\n",
    "\n",
    "    print(\"Cleaning up\")\n",
    "    # Deleting the tiff from memory\n",
    "    os.remove(f\"naip_temp.tif\")\n",
    "    print(\"Complete\")\n",
    "\n",
    "    return {\"dltile\": dltile_key, \"data\": out_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd15e981-2cce-46f9-8497-4cd61978ba44",
   "metadata": {},
   "source": [
    "Now we format our input arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a65a3d2-1704-4231-9129-2a8169ab1ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = [[dltile.key] for dltile in dltiles]\n",
    "len(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526c93d-9516-4300-b2ac-15a814d70256",
   "metadata": {},
   "source": [
    "Now that it's all packaged up into a function, we can test it locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f73dd3-7170-4df9-9ebc-5e1de12abdcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(get_pixel_values(dltiles[0].key)[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b672fc-bf86-417e-979d-7d5c49e710ec",
   "metadata": {},
   "source": [
    "Once we are happy with the performance of our function we can save it to our Compute service.\n",
    "\n",
    "Note here that we must pass geopandas as a requirement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3cd19a-840d-49a6-b759-5c9f7045eae6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async_func = Function(\n",
    "    get_pixel_values,\n",
    "    name=func_name,\n",
    "    image=\"python3.9:latest\",\n",
    "    cpus=1,\n",
    "    memory=2,\n",
    "    timeout=900,\n",
    "    maximum_concurrency=20,\n",
    "    retry_count=1,\n",
    "    requirements=[\"descarteslabs-vector\", \"geopandas\"],\n",
    ")\n",
    "\n",
    "async_func.save()\n",
    "print(f\"Saved {async_func.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b7e77-92b1-4986-b357-bad826de7e9c",
   "metadata": {},
   "source": [
    "**_Take note of your Function ID!_**\n",
    "\n",
    "And finally map args to our Function to return a set of jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d6d76-21c6-4783-918c-a6dd7f2f7334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobs = async_func.map(args)\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed64a26e-4def-4781-bf5a-45e18d5c0231",
   "metadata": {
    "tags": []
   },
   "source": [
    "Navigate to [app.descarteslabs.com/compute](https://app.descarteslabs.com/compute) to track your progress.\n",
    "\n",
    "Or wait programmatically via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5238dc-0c8a-47c6-b354-9640dc372d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async_func.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5245a4-b5f4-4dcb-8597-757bd4be7f7f",
   "metadata": {},
   "source": [
    "Once this function completes, you can move on to [02b Training a Supervised Classifier.ipynb](02b%20Training%20a%20Supervised%20Classifier.ipynb) to retrieve the results and train our model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a86579-a93d-4f05-9760-9de283b04a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
