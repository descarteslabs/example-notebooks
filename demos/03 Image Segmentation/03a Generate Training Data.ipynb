{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe45fcb6-ddc4-4c7d-8ccb-c3738c9d0b03",
   "metadata": {},
   "source": [
    "# Computer Vision on the Descartes Labs Platform - Generate Training Data\n",
    "__________________\n",
    "This notebook will demonstrate how one can utilize Descartes Labs Python APIs to efficiently prototype and iterate on training data generation for an image segmentation model. This is meant to serve _solely as a jumping off point_ and is not intended to be used as a panacea for all machine learning needs.\n",
    "\n",
    "The general outline of this sample is as follows:\n",
    "* Explore our study area interactively with [`Dynamic Compute`](https://docs.descarteslabs.com/api/dynamic-compute.html), including:\n",
    "    * Reading in a table of training features as a [`Vector`](https://docs.descarteslabs.com/api/vector.html) table, in this sample we will look at wellpads in West Texas\n",
    "    * Overlaying [National Agricultural Imagery Program (NAIP)](https://app.descarteslabs.com/explorer/datasets/usda:naip:v1) high resolution optical imagery for our model input\n",
    "* Split up the study area into [`DLTile`](https://docs.descarteslabs.com/descarteslabs/geo/readme.html#descarteslabs.geo.DLTile)s\n",
    "* Define an asynchronous [`Function`](https://docs.descarteslabs.com/descarteslabs/compute/readme.html#descarteslabs.compute.Function) to map over each tile, which:\n",
    "    * Searches and retrieves NAIP imagery from [`Catalog`](https://docs.descarteslabs.com/descarteslabs/catalog/readme.html)\n",
    "    * Masks the imagery to the intersecting training features\n",
    "    * Returns the corresponding **nir**, **red**, and **green** band values and feature masks\n",
    "* Retrieve and format results of the function for input into a tensorflow model in [03b Training a Segmentation Model.ipynb](03b%20Training%20a%20Segmentation%20Model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451ef53-c400-4700-bad7-95104cde183e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import descarteslabs as dl\n",
    "from descarteslabs.catalog import Blob, Product, Image, properties as p\n",
    "from descarteslabs.compute import Function, Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ae4c8-a273-4f2c-9499-f08fcd52b075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import descarteslabs.dynamic_compute as dc\n",
    "from descarteslabs.vector import Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c9474a-7adc-4ffc-a423-2220cb436dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, os, rasterio, sys\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from rasterio.mask import raster_geometry_mask\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e3b47-f85e-4e8c-b213-37379e515727",
   "metadata": {},
   "source": [
    "Defining global variables, including NAIP Product ID and a Function name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5c3ed-8afd-4cd3-bda7-5a57aa257d34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naip_pid = \"usda:naip:v1\"\n",
    "wellpad_tid = \"descarteslabs:wellpad-example-training-data\"\n",
    "func_name = \"Pull Wellpad Training Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8d66a-946b-4512-8bec-c7669c5c9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "major = sys.version_info.major\n",
    "minor = sys.version_info.minor\n",
    "compute_image = f\"python{major}.{minor}:latest\"\n",
    "compute_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72799b9e-5437-41b1-b371-305383d167ff",
   "metadata": {},
   "source": [
    "## Setting the Scene with Dynamic Compute\n",
    "\n",
    "Here we will set up an interactive map to explore our study area in more detail. In the subsequent cells we will visualize the training feature collection, a series of 1000 outline wellpads in West Texas, and overlay them on top of 1m resolution NAIP imagery collected in 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54698362-a7bd-48d3-be3c-9dc0231068ff",
   "metadata": {},
   "source": [
    "Setting up an ipyleaflet map, including center coordinates and zoom level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3f0c0-4c5c-4dbc-8296-8ffe06163098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = dc.map\n",
    "\n",
    "m.center = 33.4730, -101.4974\n",
    "m.zoom = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a09e78-1071-4d5e-8804-ab9d7eddb015",
   "metadata": {},
   "source": [
    "Create a Mosaic of NAIP Imagery for our time period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad7ec4-9a40-4afc-a9ad-9681333aa922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naip_mosaic = dc.Mosaic.from_product_bands(\n",
    "    naip_pid, \"nir red green\", start_datetime=\"2016-01-01\", end_datetime=\"2017-01-01\"\n",
    ")\n",
    "naip_mosaic.visualize(\"NAIP FCC\", m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af62e4d0-3b8a-44c9-84bf-735f2d2071b7",
   "metadata": {},
   "source": [
    "Then get and and visualize our training features table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29484630-2fbf-4cb6-9497-6ad12a5a7d67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wellpad_table = Table.get(wellpad_tid)\n",
    "wellpad_table.visualize(\"Wellpads\", m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e992dcc-888a-4593-bda9-fee29074b2fb",
   "metadata": {},
   "source": [
    "And finally instantiate our map frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2dc03-df7d-4f81-98f4-e3f97ab9e334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb4441-e73f-4d4b-bf3b-fec60bfad5f4",
   "metadata": {},
   "source": [
    "## Tiling \n",
    "\n",
    "Here we will create a list of tiles for our area. First, retrieve the table as a geodataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d481ec-2426-43b0-8e81-7af8f3344e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "wellpad_gdf = wellpad_table.collect()\n",
    "wellpad_gdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b2cb6-2b8a-469a-aa81-15c99a5b69f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dltiles = [\n",
    "    dl.geo.DLTile.from_latlon(\n",
    "        i.centroid.y, i.centroid.x, resolution=1.0, tilesize=256, pad=0\n",
    "    )\n",
    "    for i in wellpad_gdf.geometry.tolist()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed62104-1599-450f-894d-e14c1a4a7de6",
   "metadata": {},
   "source": [
    "### _Note on tiling:_\n",
    "_In the above example we simply demonstrate one way of tiling up your AOIs. In practice the ideal method may vary depending on both the dimensions and distribution of your training data._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe136e-d83a-4b9a-879c-172fa7547738",
   "metadata": {},
   "source": [
    "## Feature Masking - Generating Training Data with Tiles\n",
    "Next up we will go through the methodology of generating our training inputs step by step before defining our asynchronous function:\n",
    "* Catalog search NAIP imagery for each tile\n",
    "* Download imagery as geotiff\n",
    "* Clip input training features to the image\n",
    "* Mask input features to image\n",
    "* Return mask and array values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935633f-954c-4e0b-8642-b199defb5a29",
   "metadata": {},
   "source": [
    "Search NAIP imagery over a sample tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4c909-c1f0-411c-b20e-adb0ed317986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naip_prod = Product.get(naip_pid)\n",
    "naip_search = naip_prod.images()\n",
    "naip_ic = (\n",
    "    naip_search.intersects(dltiles[0]).filter(\"2016-01-01\" < p.acquired < \"2017-01-01\")\n",
    ").collect()\n",
    "naip_ic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009cd22-88cd-410c-9b08-71a6b1bd0c3e",
   "metadata": {},
   "source": [
    "Download mosaic as a GeoTIFF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d803d884-7e33-4e8c-ac0a-a67b5298f5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naip_ic.download_mosaic([\"nir\", \"red\", \"green\"], dest=\"temp.tif\", format=\"tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e993b8f7-175d-43d4-a254-f7117d658387",
   "metadata": {},
   "source": [
    "Clip training features to DLTile extent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af9b545-fe04-4fe4-995f-1849d070933b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip_table = Table.get(wellpad_tid, aoi=dltiles[0])\n",
    "clip_gdf = clip_table.collect().to_crs(dltiles[0].crs)\n",
    "clip_gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fad71c-ca1b-4acf-9d1b-ae9c9127c8bd",
   "metadata": {},
   "source": [
    "Mask input feature to the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31408899-489e-4722-915b-f972d84cdff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 3), nrows=1, ncols=4)\n",
    "with rasterio.open(\"temp.tif\", \"r+\") as in_ds:\n",
    "    out_msk, out_trans, out_wind = raster_geometry_mask(\n",
    "        in_ds,\n",
    "        clip_gdf.geometry.tolist(),\n",
    "    )\n",
    "    arr = in_ds.read()\n",
    "    out_data = {}\n",
    "    for i, band in enumerate([\"nir\", \"red\", \"green\"]):\n",
    "        band_arr = arr[i, :, :]\n",
    "        msk_band_arr = np.ma.masked_where(out_msk, band_arr)\n",
    "        ax[i].imshow(msk_band_arr)\n",
    "        ax[i].set_title(band + \" masked\")\n",
    "    ax[3].imshow(out_msk)\n",
    "    ax[3].set_title(\"mask\")\n",
    "os.remove(\"temp.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06039dd2-6c74-4e9c-b8bc-19419a4cc7e2",
   "metadata": {},
   "source": [
    "## Scaling with Batch Compute\n",
    "\n",
    "Now that we've covered the methodology, we can wrap the above code into a self-contained Python function to then send to our Batch Compute service. In the below example the only input argument is a single tile key, and the function returns a dictionary containing the input band values and their associated feature masks as lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f932b2-f93d-4ecb-8d20-e476166c75c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pull_training_data(dltile_key):\n",
    "    import os, rasterio, numpy as np\n",
    "    from rasterio.mask import mask, raster_geometry_mask\n",
    "\n",
    "    from descarteslabs.catalog import Product, properties as p\n",
    "    import descarteslabs as dl\n",
    "    from descarteslabs.vector import Table\n",
    "\n",
    "    # Global variables\n",
    "    naip_pid = \"usda:naip:v1\"\n",
    "    bands = [\"nir\", \"red\", \"green\"]\n",
    "    wellpad_tid = f\"descarteslabs:wellpad-example-training-data\"\n",
    "    print(\"Starting process...\")\n",
    "    # Creating tile\n",
    "    dltile = dl.geo.DLTile.from_key(dltile_key)\n",
    "\n",
    "    # Retrieving features within the tile\n",
    "    local_table = Table.get(wellpad_tid, aoi=dltile)\n",
    "    local_gdf = local_table.collect().to_crs(dltile.crs)\n",
    "\n",
    "    print(\"Downloaded GDF...\")\n",
    "    # Search NAIP\n",
    "    naip_prod = Product.get(naip_pid)\n",
    "    naip_ic = (\n",
    "        naip_prod.images()\n",
    "        .intersects(dltile)\n",
    "        .filter(\"2016-01-01\" < p.acquired < \"2017-01-01\")\n",
    "    ).collect()\n",
    "    # Download imagery\n",
    "    naip_ic.download_mosaic(bands, dest=\"temp.tif\")\n",
    "    print(\"Downloaded GeoTIFF...\")\n",
    "    # Set up results dict\n",
    "    data_dict = {\"key\": dltile_key, \"data\": {}}\n",
    "    # Mask to features\n",
    "    # Open the tiff\n",
    "    print(\"Masking to features\")\n",
    "    with rasterio.open(f\"temp.tif\", \"r+\") as in_ds:\n",
    "        # Mask to features\n",
    "        out_msk, out_trans, out_wind = raster_geometry_mask(\n",
    "            in_ds,\n",
    "            local_gdf.geometry.tolist(),\n",
    "        )\n",
    "        # Read our dataset\n",
    "        arr = in_ds.read()\n",
    "        out_data = {}\n",
    "        # For each band we mask and add the associated values to our output dictionary\n",
    "        for i, band in enumerate(bands):\n",
    "            band_arr = arr[i]\n",
    "            msk_band_arr = np.ma.masked_where(out_msk, band_arr)\n",
    "            # Append masked data to our output dict\n",
    "            data_dict[\"data\"][band] = band_arr.tolist()\n",
    "\n",
    "        data_dict[\"data\"][\"mask\"] = (~out_msk).tolist()\n",
    "    print(\"Complete\")\n",
    "    # Cleaning up after ourselves\n",
    "    os.remove(\"temp.tif\")\n",
    "    # Returning our results, which will be saved as a Blob\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2242f2a7-da47-4c75-a8df-a10c05bffb25",
   "metadata": {},
   "source": [
    "It is best practice to test out your function locally to ensure things run as expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b86c13-0733-4f6b-ae5a-d6753cf9fa20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res_dict = pull_training_data(dltiles[0].key)\n",
    "fig, ax = plt.subplots(figsize=(10, 5), nrows=1, ncols=2)\n",
    "ax[0].imshow(np.array(res_dict[\"data\"][\"red\"]).reshape(256, 256))\n",
    "ax[1].imshow(np.array(res_dict[\"data\"][\"mask\"]).reshape(256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a8bcf9-261d-445c-a037-95fe2d5b9c56",
   "metadata": {},
   "source": [
    "## Creating a Compute Function\n",
    "Now that we've settled on a function we can submit it to our asynchronous Batch Compute service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8345802f-d31d-4451-b3f8-4092ad2febe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async_func = Function(\n",
    "    pull_training_data,\n",
    "    name=func_name,\n",
    "    image=compute_image,\n",
    "    cpus=1,\n",
    "    memory=2,\n",
    "    timeout=300,\n",
    "    maximum_concurrency=20,\n",
    "    retry_count=1,\n",
    "    requirements=[\n",
    "        \"geopandas\",\n",
    "        \"rasterio\",\n",
    "    ],\n",
    ")\n",
    "async_func.save()\n",
    "print(f\"Saved {async_func.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a33e2-60fd-4dde-8fc3-08cd2c1e13af",
   "metadata": {},
   "source": [
    "And submit each tile key to the function to return a list of jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7160a0e-c238-452d-9e39-c4b4ab75ecb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobs = async_func.map([[dltile.key] for dltile in dltiles])\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0e6af-5bcd-49ab-8a1e-1dade964320e",
   "metadata": {},
   "source": [
    "We now wait for our function to complete. To track progress visit [app.descarteslabs.com/compute](https://app.descarteslabs.com/compute) or wait programmatically via:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be901738-398c-4888-a4c6-4caeecb53787",
   "metadata": {},
   "source": [
    "    async_func.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2396af6-066a-479b-8f0b-6e7fb63f6360",
   "metadata": {},
   "source": [
    "## Retrieving Results\n",
    "Once your function has finished running we can read the results as blobs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f2009c-4510-4ca8-92fd-208f1ea292dd",
   "metadata": {},
   "source": [
    "If you lost your function ID, access it from [app.descarteslabs.com/compute](https://app.descarteslabs.com/compute), or search the most recently created function by that name as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e79baa-fc39-4f88-8709-de36914f2653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "func_search = (\n",
    "    Function.search()\n",
    "    .filter(p.name.startswith(func_name))\n",
    "    .sort(-Function.creation_date)\n",
    "    .limit(1)\n",
    ").collect()\n",
    "async_func = func_search[0]\n",
    "print(async_func.id)\n",
    "print(async_func.creation_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85b3e5e-73f4-407f-a6c8-a790c626a852",
   "metadata": {},
   "source": [
    "Next we search and retrieve the results of our function. This may take a few minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a35d9d-74e7-43f0-9235-9ec2b5b54a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Retrieving results for {async_func.id}\")\n",
    "res_list = []\n",
    "for b in (\n",
    "    Blob.search()\n",
    "    .filter(p.name.startswith(async_func.id))\n",
    "    .filter(p.storage_type == \"compute\")\n",
    "):\n",
    "    res_list.append(json.loads(b.data()))\n",
    "print(f\"Retrieved {len(res_list)} results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c40a05-65d8-47f1-86f2-c91d783b8e99",
   "metadata": {},
   "source": [
    "Now we concatenate our results by casting each list as numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06681a96-37a8-4c2c-9c8b-a73ac64aaf88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgb_list = [\n",
    "    np.array(\n",
    "        (res[\"data\"][\"nir\"], res[\"data\"][\"red\"], res[\"data\"][\"green\"]),\n",
    "        dtype=np.float64,\n",
    "    )\n",
    "    for res in res_list\n",
    "]\n",
    "msk_list = [np.array([res[\"data\"][\"mask\"]]) for res in res_list]\n",
    "del res_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd0c1d-7d44-4f01-8613-ae8137ed330a",
   "metadata": {},
   "source": [
    "And finally reformat and save them for input to our tensorflow model trained in [03b Training a Segmentation Model.ipynb](03b%20Training%20a%20Segmentation%20Model.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6958c443-75af-4206-b577-34b8aae3e2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_array = np.transpose(np.stack(rgb_list, axis=0), (0, 2, 3, 1))\n",
    "mask_array = np.transpose(np.stack(msk_list, axis=0), (0, 2, 3, 1))\n",
    "data_array.shape, mask_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d561c0-c76c-4eeb-b04e-1c147d61692f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"data_array.npy\", data_array)\n",
    "np.save(\"mask_array.npy\", mask_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb185a-5a10-4046-a240-54eab0124c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
