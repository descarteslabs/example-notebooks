{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99569937-eac0-4541-b079-abc599bc4d0b",
   "metadata": {},
   "source": [
    "# Timeseries Analysis with Batch Compute\n",
    "__________________\n",
    "\n",
    "This notebook will cover the typical pattern of using the Batch Compute API to scalably generate arbitrary timeseries data with Catalog. \n",
    "\n",
    "Here we will define a [`Function`](https://docs.descarteslabs.com/descarteslabs/compute/readme.html#descarteslabs.compute.Function) that calculates daily Sentinel-2 NDVI statistics, masked to the Cropland Data Layer Hops class and summarized by week, in 4 major hop producing areas in the Northwestern United States.\n",
    "\n",
    "The general methodology is as follows:\n",
    "1. Read in a geojson of Census Tract boundary data and store as a [`Blob`](https://docs.descarteslabs.com/descarteslabs/catalog/docs/blob.html#descarteslabs.catalog.Blob)\n",
    "2. Define a Python function that takes a GEOID and date as input parameters and:\n",
    "    * Searches Sentinel-2 scenes over the specified date ranges\n",
    "    * Mosaics Sentinel-2 Images and the Cropland Data Layer as ndarrays\n",
    "    * Calculates NDVI and masks to the Hops class\n",
    "    * Returns the mean NDVI value for the specified date. If no data is present, returns NaN\n",
    "3. Submit the local function to [`Compute`](https://docs.descarteslabs.com/descarteslabs/compute/readme.html) and monitor the status\n",
    "4. Retrieve the time series results as a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309de25b-1889-4a35-9029-af85575ee030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import descarteslabs as dl\n",
    "from descarteslabs.catalog import Blob, Image, Product, properties as p\n",
    "from descarteslabs.compute import Function, Job\n",
    "from descarteslabs.exceptions import ConflictError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb811616-51ab-487a-9b0e-0a09d9128e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5514632-2f6c-4e43-b877-be61981c2856",
   "metadata": {},
   "source": [
    "Defining global variables, including both Sentinel-2 ID, start and end dates, and a unique Function name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a128e45-aaa5-48db-b5a6-f54c0718f0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "org = dl.auth.Auth().payload[\"org\"]\n",
    "user_id = dl.auth.Auth().namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b457f-28c6-47cb-9197-aa028715b1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pid = \"esa:sentinel-2:l2a:v1\"\n",
    "start_date = \"2022-10-01\"\n",
    "end_date = \"2022-11-01\"\n",
    "func_name = \"Get NDVI Timeseries Values\"\n",
    "func_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50b95c-fae8-46a2-a925-14bb116c3f4b",
   "metadata": {},
   "source": [
    "Next read in our input geojson file and save it as a blob in the next cell for reference in our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fc983-2469-4aa2-9664-5b1b37a0e0ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"data/hop_tracts.geojson\")\n",
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de1a0e9-e570-4b85-a9e3-6a0f9ff109ce",
   "metadata": {},
   "source": [
    "#### **_Note on Saving Blobs:_** \n",
    "\n",
    "We do not always need to delete and overwrite our objects on every iteration as in the following cell. This notebook is designed for demonstration purposes where we do not care about preserving each prior version. \n",
    "\n",
    "In practice, as long as your blob has a **unique** ID you ignore the following cell and simply run:\n",
    "\n",
    "    blob = Blob(name=\"unique-blob-name\")\n",
    "    blob.upload_data(json.dumps(gdf.to_json()))\n",
    "    blob.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba5f3c7-620f-4ba0-b7de-585eb6866e47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create a new Blob object\n",
    "    blob = Blob(\n",
    "        name=\"hop_tracts\",\n",
    "        namespace=\"ndvi_timeseries_example_notebook\",\n",
    "        readers=[f\"org:{org}\"],\n",
    "        tags=[\"examples\"],\n",
    "    )\n",
    "    # Upload our DataFrame to this Blob:\n",
    "    blob.upload_data(json.dumps(gdf.to_json()))\n",
    "    blob.save()\n",
    "\n",
    "except ConflictError:\n",
    "    # Already exists within your org\n",
    "    blob = Blob.get(name=\"hop_tracts\", namespace=\"ndvi_timeseries_example_notebook\")\n",
    "    print(\"Blob already exists\")\n",
    "blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe369c09-4e4b-410d-be92-2bd327ba0f27",
   "metadata": {},
   "source": [
    "## Function Methodology\n",
    "These next few cells parse out the methodology contained within our function which will be defined below. \n",
    "\n",
    "The general steps are as follows:\n",
    "1. Create an [`AOI`](https://docs.descarteslabs.com/descarteslabs/geo/readme.html#descarteslabs.geo.AOI) from our input geometry\n",
    "2. Search for [Sentinel-2 L2A](https://app.descarteslabs.com/explorer/datasets/esa:sentinel-2:l2a:v1) [`ImageCollection`](https://docs.descarteslabs.com/descarteslabs/catalog/docs/image.html#descarteslabs.catalog.ImageCollection), filtered to the provided AOI and date range\n",
    "3. Create an Image object of the USDA [Cropland Data Layer](https://app.descarteslabs.com/explorer/datasets/usda:cdl:v1) 2022 classification\n",
    "4. Retrieve the associated __nir__ and __red__ bands for Sentinel-2 and class band for CDL as ndarrays\n",
    "5. Calculate NDVI, mask to the hops class in the CDL array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713c68ba-e3f9-4e40-9069-d2ad5d9336e9",
   "metadata": {},
   "source": [
    "Defining an AOI object out of one of our geojson features, alongside output raster metadata parameters (resolution, output CRS). Here we will look at the census tract for Moxee, WA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6186b7-f51c-497b-8651-23ddc8dee6e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moxee_geom = gdf.loc[gdf[\"GEOID\"] == \"53077001702\"][\"geometry\"].values[0]\n",
    "aoi = dl.geo.AOI(moxee_geom, resolution=30.0, crs=\"EPSG:3857\")\n",
    "aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afecfb6-d5b5-48b4-bd68-8b41aa5d9cbd",
   "metadata": {},
   "source": [
    "Searching Catalog for Sentinel-2 Imagery, chaining intersects and filter methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120e854-420f-46a8-aaa6-48836a0907fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_ic = (\n",
    "    Product.get(pid)\n",
    "    .images()\n",
    "    .intersects(aoi)\n",
    "    .filter(\"2022-10-01\" <= p.acquired <= \"2022-10-02\")\n",
    "    .sort(\"acquired\")\n",
    "    .limit(None)\n",
    ").collect()\n",
    "s2_ic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9c7c1-aee9-48e2-afc5-7ea5e4c0801d",
   "metadata": {},
   "source": [
    "Retrieve a single Image from our 2022 Cropland Data Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61bf36-da01-4dce-befe-bee7970993bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdl_image = Image.get(\"usda:cdl:v1:meta_2022_30m_cdls_v1\")\n",
    "cdl_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7548723b-0f30-4e42-83db-8ca05431d519",
   "metadata": {},
   "source": [
    "#### _**Note on Metadata Limits**_: \n",
    "\n",
    "In the above example we are accessing a single CONUS-wide CDL [`Image`](https://docs.descarteslabs.com/descarteslabs/catalog/docs/image.html#descarteslabs.catalog.Image), as opposed to searching over a collection. In some cases this practice is optimal to avoid unnecessary search/filter steps as to avoid rate limits. [Please refer to the Quotas and Limits page for more details on metadata search and retrieval limits.](https://docs.descarteslabs.com/guides/quota.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00f64c-5af6-412d-a83c-5245d575bcb3",
   "metadata": {},
   "source": [
    "Next we return our pixel data as ndarrays by mosaicking our imagery and retrieving the ndarray of our CDL image. Note, we are using the _**same AOI**_ in both cases, to ensure a matching geotransform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b260cc-ce2c-42d7-bbb9-51ef9b24461b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_arr = s2_ic.mosaic(bands=[\"nir\", \"red\"])\n",
    "cdl_arr = cdl_image.ndarray(bands=[\"class\"], geocontext=s2_ic.geocontext)\n",
    "\n",
    "s2_arr.shape, cdl_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a63f2f-c700-4f38-a950-9740149ddd89",
   "metadata": {},
   "source": [
    "Calculate NDVI, mask to the Hop CDL value 56:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd598a-47cd-44a5-b3e0-3feb1f573d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculating NDVI\n",
    "nir = s2_arr[0, :, :]\n",
    "red = s2_arr[1, :, :]\n",
    "cdl = cdl_arr[0, :, :]\n",
    "\n",
    "ndvi = (nir - red) / (nir + red)\n",
    "\n",
    "hop_ndvi_msk = np.ma.masked_where(cdl != 56, ndvi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd3753-e004-410b-b12c-ee71b8839ba2",
   "metadata": {},
   "source": [
    "Plotting our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d658f-5efc-44bb-80ca-65f0513e5b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "ax[0].imshow(ndvi)\n",
    "ax[0].set_title(\"NDVI\")\n",
    "ax[1].imshow(cdl, cmap=\"terrain\")\n",
    "ax[1].set_title(\"CDL\")\n",
    "ax[2].imshow(hop_ndvi_msk)\n",
    "ax[2].set_title(\"NDVI - Hop Masked\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445921d9-a11e-4dd1-9eda-a2e9f56b79c8",
   "metadata": {},
   "source": [
    "## Preparing the Compute Function\n",
    "Now that we're settled on a methodology, we can put together our Python function to pass to Batch Compute. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef5df00-5828-4588-ad42-d494bf1fd975",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here we will define our Python function. The steps have already been outlined in the above cells, just combined into a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e320876-a676-42d5-80f1-6eef8db820e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_ndvi(geoid, date):\n",
    "    import numpy as np\n",
    "    import geopandas as gpd\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "    from json import dumps, loads\n",
    "\n",
    "    import descarteslabs as dl\n",
    "    from descarteslabs.catalog import Blob, Image, Product, properties as p\n",
    "\n",
    "    pid = \"esa:sentinel-2:l2a:v1\"\n",
    "    cdl_pid = \"usda:cdl:v1\"\n",
    "\n",
    "    # Getting this and next date\n",
    "    date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    next_date = date + timedelta(days=1)\n",
    "\n",
    "    # Retrieve our GDF from a Blob\n",
    "    geom_blob = Blob.get(\n",
    "        name=\"hop_tracts\", namespace=\"ndvi_timeseries_example_notebook\"\n",
    "    )\n",
    "    # Load our GDF\n",
    "    geom_data = loads(geom_blob.data())\n",
    "    gdf = gpd.read_file(geom_data)\n",
    "\n",
    "    print(\"Pulled down GDF from Storage Blob\")\n",
    "\n",
    "    # Retrieve single geometry from GEOID passed\n",
    "    in_geom = gdf[gdf[\"GEOID\"] == geoid].iloc[0][\"geometry\"]\n",
    "\n",
    "    # Create AOI from geometry\n",
    "    aoi = dl.geo.AOI(in_geom, resolution=30.0, crs=\"EPSG:3857\")\n",
    "\n",
    "    # Search Sentinel2 for our date ranges\n",
    "\n",
    "    print(f\"Searching {date.strftime('%Y-%m-%d')} to {next_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    s2_ic = (\n",
    "        Product.get(pid)\n",
    "        .images()\n",
    "        .intersects(aoi)\n",
    "        .filter(date <= p.acquired < next_date)\n",
    "        .sort(\"acquired\")\n",
    "        .limit(None)\n",
    "    ).collect()\n",
    "\n",
    "    # End if we have no imagery satisfying our filter conditions:\n",
    "    try:\n",
    "        assert len(s2_ic) > 0\n",
    "    except:\n",
    "        result_dict = {\n",
    "            \"GEOID\": geoid,\n",
    "            \"mean_ndvi\": np.nan,\n",
    "            \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "        }\n",
    "        print(\"No images found\")\n",
    "        return result_dict\n",
    "\n",
    "    print(f\"Found {len(s2_ic)} images\")\n",
    "\n",
    "    # Get CDL Image\n",
    "    cdl_image = Image.get(\"usda:cdl:v1:meta_2022_30m_cdls_v1\")\n",
    "\n",
    "    ##Mosaic and ndarray our image data to the *same GeoContext*\n",
    "    s2_arr = s2_ic.mosaic(bands=[\"nir\", \"red\"], data_type=\"Float32\", geocontext=aoi)\n",
    "    cdl_arr = cdl_image.ndarray(bands=[\"class\"], geocontext=aoi)\n",
    "\n",
    "    print(\"Rastered imagery\")\n",
    "\n",
    "    # Calculating NDVI, then mask to Hop Class 56\n",
    "    nir = s2_arr[0, :, :]\n",
    "    red = s2_arr[1, :, :]\n",
    "    cdl = cdl_arr[0, :, :]\n",
    "\n",
    "    ndvi = (nir - red) / (nir + red)\n",
    "\n",
    "    hop_ndvi_msk = np.ma.masked_where(cdl != 56, ndvi)\n",
    "\n",
    "    # Returning mean\n",
    "    mean_ndvi = float(hop_ndvi_msk.mean())\n",
    "\n",
    "    print(\"Completed calculation\")\n",
    "\n",
    "    result_dict = {\n",
    "        \"GEOID\": geoid,\n",
    "        \"mean_ndvi\": mean_ndvi,\n",
    "        \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681bdd2d-e4eb-43e7-8ad1-00656ca680ac",
   "metadata": {},
   "source": [
    "Next we'll define our input arguments for our function:\n",
    "1. Generate a list of dates between our start and end dates\n",
    "2. Generate a tuple of (GEOID, date) for each GEOID in our Census Tracts GDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80a40b-f944-46b3-af1e-bfbdd8830936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_list = pd.date_range(start_date, end_date).strftime(\"%Y-%m-%d\").tolist()\n",
    "geoids = gdf[\"GEOID\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524d298-7800-42df-9c32-140cd1216fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = [args for args in itertools.product(geoids, date_list)]\n",
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbfc61a-c9e0-4c58-b019-e296b2cc16c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1676cbd0-d99c-4ed9-a365-dee96cfdab9c",
   "metadata": {},
   "source": [
    "Let's test a run of this function locally, before we submit our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce27999-28bf-46b5-99c9-86663d85c00e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "return_ndvi(*params[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8397a32-64ac-416b-ba5d-b7db83fc9643",
   "metadata": {},
   "source": [
    "## Creating the Compute Function\n",
    "We can now create our [`Function`](https://docs.descarteslabs.com/descarteslabs/compute/readme.html#descarteslabs.compute.Function) object. \n",
    "\n",
    "Below we will pass several scaling parameters and save our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e906c85e-a820-409d-abf1-df09828f9cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async_func = Function(\n",
    "    return_ndvi,\n",
    "    name=func_name,\n",
    "    image=\"python3.9:latest\",\n",
    "    cpus=0.5,\n",
    "    memory=2,\n",
    "    timeout=900,\n",
    "    maximum_concurrency=50,\n",
    "    retry_count=2,\n",
    ")\n",
    "\n",
    "async_func.save()\n",
    "print(f\"Saved {async_func.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8ac5b2-c4d2-42f5-978c-84c3c07a71d0",
   "metadata": {},
   "source": [
    "Now we can submit our arguments to our function and return a list of [`Job`](https://docs.descarteslabs.com/descarteslabs/compute/readme.html#descarteslabs.compute.Job)s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da2ba9-1c31-4fcf-8e20-50f87978e571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobs = async_func.map(params)\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970be74-73f7-4695-85b2-5d000e8122c9",
   "metadata": {},
   "source": [
    "## Waiting for Completion\n",
    "We now wait for our jobs to complete. There are several ways to do this, such as waiting programmatically via:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a0b2be-672a-4e23-b465-99baaf19000f",
   "metadata": {
    "tags": []
   },
   "source": [
    "    async_func.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a526eec1-23cd-464b-adb4-24145189194e",
   "metadata": {},
   "source": [
    "You can also track your progress at [app.descarteslabs.com/compute](https://app.descarteslabs.com/compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be764aea-0ec5-483a-836b-27bed59ac384",
   "metadata": {},
   "source": [
    "## Retrieving Results\n",
    "Once our function is completed, we can retrieve our result dictionaries as blobs by structuring the resulting IDs, as outlined in [01 Hello World.ipynb](01%20Hello%20World.ipynb):\n",
    "\n",
    "    compute/{namespace}/{function-id}/{job-id}\n",
    "\n",
    "Where the namespace is:\n",
    "\n",
    "    {org}:{user-id}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47f233-21b5-4be4-8824-1fc50f23ed08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Results for {async_func.id}\")\n",
    "res_list = []\n",
    "for b in (\n",
    "    Blob.search()\n",
    "    .filter(p.namespace == f\"{org}:{user_id}\")\n",
    "    .filter(p.name.startswith(async_func.id))\n",
    "    .filter(p.storage_type == \"compute\")\n",
    "):\n",
    "    print(f\"ID: {b.id}\")\n",
    "    res_list.append(json.loads(b.data()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ae59d-1365-4834-9fa2-4357c6bdb204",
   "metadata": {},
   "source": [
    "Once all the results are returned, we can combine them into our timeseries dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecdf7da-a6d6-417d-9072-5b5f00a17789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res_list)\n",
    "fig, ax = plt.subplots()\n",
    "res_df[\"date\"] = pd.to_datetime(res_df[\"date\"])\n",
    "\n",
    "week_df = (\n",
    "    res_df.groupby(\"GEOID\")\n",
    "    .resample(\"W-Mon\", on=\"date\")[\"mean_ndvi\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "for geoid, geoid_df in week_df.groupby(\"GEOID\"):\n",
    "    geoid_df.plot(\"date\", \"mean_ndvi\", ax=ax, label=f\"GEOID:{geoid}\")\n",
    "ax.set_title(\"NDVI\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994d5c0",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "It is always best practice to clean up after ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e724fe-5f40-462d-8a5d-e536cbebf30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async_func.delete_jobs(delete_results=True)\n",
    "async_func.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265deed3-c25a-4d42-b0ac-56e500d62463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
