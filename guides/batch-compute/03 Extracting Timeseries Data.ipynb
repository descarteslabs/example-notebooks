{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99569937-eac0-4541-b079-abc599bc4d0b",
   "metadata": {},
   "source": [
    "# Batch Compute Timeseries Analysis\n",
    "In this notebook we will demonstrate how one can utilize the `Batch Compute API` to scalable generate arbitrary timeseries statistics using `Catalog`. This notebook will define a `Function` that calculates daily Sentinel-2 NDVI statistics, masked to the Cropland Data Layer Hops class and summarized by week, in 4 major hop producing areas in the Northwestern United States.\n",
    "\n",
    "The general methodology is as follows:\n",
    "1. Read in GeoJSON of Census Tract boundary data and store onto `Descartes Labs Catalog`\n",
    "2. Define a Compute Function that:\n",
    "    * Takes a GEOID and date as input parameters\n",
    "    * Searches Sentinel-2 scenes over the specified date ranges\n",
    "    * Mosaics Sentinel-2 Images and the Cropland Data Layer as ndarrays\n",
    "    * Calculates NDVI and masks to the Hops class\n",
    "    * Returns the mean NDVI value for the specified date. If no data is present, return NaN\n",
    "3. Submit arguments to the Compute Function and monitor the status\n",
    "4. Retrieve the time series results as a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309de25b-1889-4a35-9029-af85575ee030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import descarteslabs as dl\n",
    "from descarteslabs.catalog import Blob, Image, Product, properties as p\n",
    "from descarteslabs.compute import Function, Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb811616-51ab-487a-9b0e-0a09d9128e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5514632-2f6c-4e43-b877-be61981c2856",
   "metadata": {},
   "source": [
    "Setting global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b457f-28c6-47cb-9197-aa028715b1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pid = \"esa:sentinel-2:l2a:v1\"\n",
    "cdl_pid = \"usda:cdl:v1\"\n",
    "hop_cdl_value = 56\n",
    "start_date = \"2022-10-01\"\n",
    "end_date = \"2022-11-01\"\n",
    "func_name = f\"Get NDVI Timeseries Values {datetime.today().strftime('%Y-%m-%d')}\"\n",
    "func_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50b95c-fae8-46a2-a925-14bb116c3f4b",
   "metadata": {},
   "source": [
    "Reading in our input GeoJSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672fc983-2469-4aa2-9664-5b1b37a0e0ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"data/hop_tracts.geojson\")\n",
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe369c09-4e4b-410d-be92-2bd327ba0f27",
   "metadata": {},
   "source": [
    "### Function Methodology\n",
    "These next few cells parse out the methodology contained within our `Compute Function` which will be defined below. The general steps are as follows:\n",
    "1. Create an `AOI` from our input geometry\n",
    "2. Search for Sentinel-2 L2A `ImageCollection` using `Catalog API`, filtered to the provided AOI and date params\n",
    "3. Create an `Image` object of the Cropland Data Layer's 2022 classification\n",
    "4. Retrieve the associated `nir` and `red` bands for Sentinel-2 and `class` band for CDL as `ndarray`s\n",
    "5. Calculate NDVI, mask to the hops class in the CDL array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713c68ba-e3f9-4e40-9069-d2ad5d9336e9",
   "metadata": {},
   "source": [
    "Defining an `AOI` object out of our GeoJSON, alongside output raster metadata parameters (resolution, output CRS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6186b7-f51c-497b-8651-23ddc8dee6e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moxee_geom = gdf.loc[gdf[\"GEOID\"] == \"53077001702\"][\"geometry\"].values[0]\n",
    "aoi = dl.geo.AOI(moxee_geom, resolution=30.0, crs=\"EPSG:3857\")\n",
    "aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afecfb6-d5b5-48b4-bd68-8b41aa5d9cbd",
   "metadata": {},
   "source": [
    "Searching `Catalog` for Sentinel-2 Imagery, chaining `intersects` and `filter` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120e854-420f-46a8-aaa6-48836a0907fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_ic = (\n",
    "    Product.get(pid)\n",
    "    .images()\n",
    "    .intersects(aoi)\n",
    "    .filter(\"2022-10-01\" <= p.acquired <= \"2022-10-02\")\n",
    "    .sort(\"acquired\")\n",
    "    .limit(None)\n",
    ").collect()\n",
    "s2_ic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e9c7c1-aee9-48e2-afc5-7ea5e4c0801d",
   "metadata": {},
   "source": [
    "Retrieve an `Image` of our 2022 Cropland Data Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61bf36-da01-4dce-befe-bee7970993bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cdl_image = Image.get(\"usda:cdl:v1:meta_2022_30m_cdls_v1\")\n",
    "cdl_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00f64c-5af6-412d-a83c-5245d575bcb3",
   "metadata": {},
   "source": [
    "Retrieve our pixel data as `ndarray`s via `.mosaic` on our `ImageCollection` and `.ndarary` on our `Image`. Note, we are using the _same `AOI`_ in both cases, to ensure a matching geotransform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b260cc-ce2c-42d7-bbb9-51ef9b24461b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_arr = s2_ic.mosaic(bands=[\"nir\", \"red\"], data_type=\"Float32\")\n",
    "\n",
    "cdl_arr = cdl_image.ndarray(bands=[\"class\"], geocontext=s2_ic.geocontext)\n",
    "\n",
    "s2_arr.shape, cdl_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a63f2f-c700-4f38-a950-9740149ddd89",
   "metadata": {},
   "source": [
    "Caluclate NDVI, mask to the Hop CDL value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd598a-47cd-44a5-b3e0-3feb1f573d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculating NDVI\n",
    "nir = s2_arr[0, :, :]\n",
    "red = s2_arr[1, :, :]\n",
    "cdl = cdl_arr[0, :, :]\n",
    "\n",
    "ndvi = (nir - red) / (nir + red)\n",
    "\n",
    "hop_ndvi_msk = np.ma.masked_where(cdl != hop_cdl_value, ndvi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd3753-e004-410b-b12c-ee71b8839ba2",
   "metadata": {},
   "source": [
    "Plotting our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d658f-5efc-44bb-80ca-65f0513e5b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20, 10))\n",
    "ax[0].imshow(ndvi)\n",
    "ax[0].set_title(\"NDVI\")\n",
    "ax[1].imshow(cdl, cmap=\"terrain\")\n",
    "ax[1].set_title(\"CDL\")\n",
    "ax[2].imshow(hop_ndvi_msk)\n",
    "ax[2].set_title(\"Hop Masked NDVI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445921d9-a11e-4dd1-9eda-a2e9f56b79c8",
   "metadata": {},
   "source": [
    "### Preparing Batch Compute Function\n",
    "Now that we're settled on a methodology, we can put together our Python function to pass to `Batch Compute`. First, we will store our GeoJSON GeoDataFrame to a `DL Storage Blob` for retrieval in our concurrent environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d4c46-f6a7-4a48-8a06-0218c32c4128",
   "metadata": {},
   "outputs": [],
   "source": [
    "org = dl.auth.Auth().payload[\"org\"]\n",
    "try:\n",
    "    # Create a new Blob object\n",
    "    blob = Blob(\n",
    "        name=\"hop_tracts\",\n",
    "        namespace=\"ndvi_timeseries_example_notebook\",\n",
    "        readers=[f\"org:{org}\"],\n",
    "        tags=[\"examples\"],\n",
    "    )\n",
    "    # Upload our DataFrame to this Blob:\n",
    "    blob.upload_data(json.dumps(gdf.to_json()))\n",
    "    blob.save()\n",
    "\n",
    "except:\n",
    "    # Already exists within your org\n",
    "    blob = Blob.get(name=\"hop_tracts\", namespace=\"ndvi_timeseries_example_notebook\")\n",
    "    print(\"Blob already exists\")\n",
    "blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef5df00-5828-4588-ad42-d494bf1fd975",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next we will define our Python function. The steps have already been outlined in the above cells, just combined into a single function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e320876-a676-42d5-80f1-6eef8db820e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_ndvi(args):\n",
    "    import numpy as np\n",
    "    import geopandas as gpd\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "    from json import dumps, loads\n",
    "\n",
    "    import descarteslabs as dl\n",
    "    from descarteslabs.catalog import Blob, Image, Product, properties as p\n",
    "\n",
    "    # Unpack args\n",
    "    geoid, date = args\n",
    "\n",
    "    # Getting this and next date\n",
    "    date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    next_date = date + timedelta(days=1)\n",
    "\n",
    "    # Retrieve our GDF\n",
    "    geom_blob = Blob.get(\n",
    "        name=\"hop_tracts\", namespace=\"ndvi_timeseries_example_notebook\"\n",
    "    )\n",
    "\n",
    "    geom_data = loads(geom_blob.data())\n",
    "    gdf = gpd.read_file(geom_data)\n",
    "\n",
    "    print(\"Pulled down GDF from Storage Blob\")\n",
    "\n",
    "    in_geom = gdf[gdf[\"GEOID\"] == geoid].iloc[0][\"geometry\"]\n",
    "\n",
    "    # Create AOI from GDF\n",
    "    aoi = dl.geo.AOI(in_geom, resolution=30.0, crs=\"EPSG:3857\")\n",
    "    # Search Sentinel2 for our date ranges\n",
    "    pid = \"esa:sentinel-2:l2a:v1\"\n",
    "    cdl_pid = \"usda:cdl:v1\"\n",
    "\n",
    "    print(f\"Searching {date.strftime('%Y-%m-%d')} to {next_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    s2_ic = (\n",
    "        Product.get(pid)\n",
    "        .images()\n",
    "        .intersects(aoi)\n",
    "        .filter(date <= p.acquired < next_date)\n",
    "        .sort(\"acquired\")\n",
    "        .limit(None)\n",
    "    ).collect()\n",
    "\n",
    "    # End if we have no imagery satisfying our filter conditions:\n",
    "    try:\n",
    "        assert len(s2_ic) > 0\n",
    "    except:\n",
    "        result_dict = {\n",
    "            \"GEOID\": geoid,\n",
    "            \"mean_ndvi\": np.nan,\n",
    "            \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "        }\n",
    "        return result_dict\n",
    "\n",
    "    print(f\"Found {len(s2_ic)} images\")\n",
    "\n",
    "    # Get CDL Image\n",
    "    cdl_image = Image.get(\"usda:cdl:v1:meta_2022_30m_cdls_v1\")\n",
    "\n",
    "    ##Mosaic and ndarray our image data to the _same GeoContext_\n",
    "    s2_arr = s2_ic.mosaic(bands=[\"nir\", \"red\"], data_type=\"Float32\", geocontext=aoi)\n",
    "\n",
    "    cdl_arr = cdl_image.ndarray(bands=[\"class\"], geocontext=aoi)\n",
    "    print(\"Rastered imagery\")\n",
    "\n",
    "    # Calculating NDVI, masking to Hop Class 56\n",
    "    nir = s2_arr[0, :, :]\n",
    "    red = s2_arr[1, :, :]\n",
    "    cdl = cdl_arr[0, :, :]\n",
    "\n",
    "    ndvi = (nir - red) / (nir + red)\n",
    "    hop_ndvi_msk = np.ma.masked_where(cdl != 56, ndvi)\n",
    "\n",
    "    # Returning mean\n",
    "    mean_ndvi = float(hop_ndvi_msk.mean())\n",
    "\n",
    "    print(\"Completed calculation\")\n",
    "\n",
    "    result_dict = {\n",
    "        \"GEOID\": geoid,\n",
    "        \"mean_ndvi\": mean_ndvi,\n",
    "        \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681bdd2d-e4eb-43e7-8ad1-00656ca680ac",
   "metadata": {},
   "source": [
    "Next we'll define our input arguments for our `Compute Function`:\n",
    "1. Generate a list of dates between our start and end dates\n",
    "2. Generate a tuple of (GEOID, date) for each GEOID in our Census Tracts GDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80a40b-f944-46b3-af1e-bfbdd8830936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_list = pd.date_range(start_date, end_date).strftime(\"%Y-%m-%d\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524d298-7800-42df-9c32-140cd1216fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = [(geoid, date) for geoid in gdf[\"GEOID\"].tolist() for date in date_list]\n",
    "len(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1676cbd0-d99c-4ed9-a365-dee96cfdab9c",
   "metadata": {},
   "source": [
    "Let's test a run of this function locally, before we submit to `Compute`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce27999-28bf-46b5-99c9-86663d85c00e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "return_ndvi(params[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8397a32-64ac-416b-ba5d-b7db83fc9643",
   "metadata": {},
   "source": [
    "### Creating Batch Compute Function\n",
    "We can now create our `Function` object. Below we will pass several scaling parameters and `save` our `Function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e906c85e-a820-409d-abf1-df09828f9cb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async_func = Function(\n",
    "    return_ndvi,\n",
    "    name=func_name,\n",
    "    image=\"python3.9:latest\",\n",
    "    cpus=1,\n",
    "    memory=2,\n",
    "    timeout=900,\n",
    "    maximum_concurrency=50,\n",
    "    retry_count=2,\n",
    "    requirements=[\"geopandas\"],\n",
    ")\n",
    "async_func.save()\n",
    "print(f\"Saved {async_func.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4062c6-ac51-4764-813b-2a8d107c3ded",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can submit `Job`s to our `Function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4369ac2-cdd9-47af-969a-6d1c0c6320b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobs = []\n",
    "for param in params:\n",
    "    job = async_func(param)\n",
    "    jobs.append(job)\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970be74-73f7-4695-85b2-5d000e8122c9",
   "metadata": {},
   "source": [
    "### Waiting for Completion\n",
    "We now wait for our `Function` to complete. We can do that on the `Function`-level or the `Job` level:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9273ab9-dd1c-4497-9154-cd6b133e7a19",
   "metadata": {},
   "source": [
    "async_func.wait_for_completion()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddcd2ae4-c48d-4d99-9419-7821a44af60d",
   "metadata": {
    "tags": []
   },
   "source": [
    "for job in jobs:\n",
    "    job.wait_for_completion()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b7ac88-ea9d-4646-9932-5bcef376804b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Waiting for Completion\n",
    "Now that we've mapped our arguments to `Job`s, we can wait for our `Function` to complete by either navigating to [app.descarteslabs.com/monitor](https://app.descarteslabs.com/monitor) or programmatically via:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fce30081-1c77-433f-ac35-e5f66a17ed82",
   "metadata": {},
   "source": [
    "async_func.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a9fbf-b98b-4f7c-a45f-7acf35782f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\"https://app.descarteslabs.com/monitor\", width=1000, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be764aea-0ec5-483a-836b-27bed59ac384",
   "metadata": {},
   "source": [
    "### Retrieving Results\n",
    "Once our `Function` is completed, we can retrieve our result dictionaries via `Storage Blob`s by structuring the resulting IDs:\n",
    "* User Org\n",
    "* User Hash\n",
    "* Function ID\n",
    "* Job ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349053fc-0df4-46aa-8b5a-17a2b24f89bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orgname = dl.auth.Auth().payload[\"org\"]\n",
    "user_hash = dl.auth.Auth().namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd47f233-21b5-4be4-8824-1fc50f23ed08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Results for {async_func.id}\")\n",
    "res_list = []\n",
    "for b in (\n",
    "    Blob.search()\n",
    "    .filter(p.namespace == f\"{orgname}:{user_hash}\")\n",
    "    .filter(p.name.startswith(async_func.id))\n",
    "    .filter(p.storage_type == \"compute\")\n",
    "):\n",
    "    print(f\"ID: {b.id}\")\n",
    "    res_list.append(json.loads(b.data()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ae59d-1365-4834-9fa2-4357c6bdb204",
   "metadata": {},
   "source": [
    "Voila!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecdf7da-a6d6-417d-9072-5b5f00a17789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res_list)\n",
    "fig, ax = plt.subplots()\n",
    "res_df[\"date\"] = pd.to_datetime(res_df[\"date\"])\n",
    "\n",
    "week_df = (\n",
    "    res_df.groupby(\"GEOID\")\n",
    "    .resample(\"W-Mon\", on=\"date\")[\"mean_ndvi\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "for geoid, geoid_df in week_df.groupby(\"GEOID\"):\n",
    "    geoid_df.plot(\"date\", \"mean_ndvi\", ax=ax, label=f\"GEOID:{geoid}\")\n",
    "ax.set_title(\"NDVI\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e724fe-5f40-462d-8a5d-e536cbebf30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd769d44-da39-40dd-b387-af1e814e557a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
