{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be841770-f5eb-4aa3-b6f4-64dd95271454",
   "metadata": {},
   "source": [
    "## Array Computation with Dynamic Compute - GeoContexts\n",
    "In previous notebooks we have explored the interactive visualization component of Dynamic Compute. Here we will dive into how and when we can extract the underlying pixel data associated with our Mosaic and ImageStack objects as numpy ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43316d33-adcb-431e-aba7-174c9e91a39f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import descarteslabs as dl\n",
    "import descarteslabs.dynamic_compute as dc\n",
    "from descarteslabs.dynamic_compute import ImageStack, Mosaic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d15b347-d3a8-4b45-9cf6-2471597f94d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Intro to GeoContexts \n",
    "Before we pull down any pixel data we must first define an area of interst (AOI) and several raster metadata parameters by which we organize our dataset. At Descartes Labs this is where the [`GeoContext`](https://docs.descarteslabs.com/descarteslabs/geo/readme.html) comes into play--we have several operators to create and utilize GeoContext objects, which we will introduce in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61597e2-1ad9-4d00-8985-9c3a0dd1b55a",
   "metadata": {},
   "source": [
    "First, we'll define an interactive map as we have in other examples and an associated *sentinel-2:l2a* Mosaic and ImageStack. Here we will be returning to [Kossuth County, Iowa's Highest Corn Producing County](https://www.nass.usda.gov/Statistics_by_State/Iowa/Publications/County_Estimates/2021/IA-CtyEst-Corn-02-21.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86da6e4-71e6-4c61-8b7a-b00aa10d4091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = dc.map\n",
    "m.center = 43.197541, -94.221831\n",
    "m.zoom = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e445d59-5053-4aef-86fa-3c000e4f6984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_mosaic = dc.Mosaic.from_product_bands(\n",
    "    \"esa:sentinel-2:l2a:v1\",\n",
    "    \"nir red green\",\n",
    "    start_datetime=\"2022-06-01\",\n",
    "    end_datetime=\"2022-7-01\",\n",
    ")\n",
    "\n",
    "s2_stack = dc.ImageStack.from_product_bands(\n",
    "    \"esa:sentinel-2:l2a:v1\",\n",
    "    \"nir red green\",\n",
    "    start_datetime=\"2022-06-01\",\n",
    "    end_datetime=\"2022-7-01\",\n",
    ").filter(lambda x: x.cloud_fraction < 0.1)\n",
    "\n",
    "s2_mosaic.visualize(\"FCC\", m)\n",
    "s2_stack.median(axis=\"images\").visualize(\"FCC-Cloudfree\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050fddbd-48a3-4e52-8b47-35419708f7a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c2163a-daa2-4cc0-ada3-1b2b926186bd",
   "metadata": {},
   "source": [
    "### Interactive Map GeoContexts\n",
    "\n",
    "The simplest GeoContext object to retrieve is that of your interactive map. We can simply call `map.geocontext()` to retrieve the current viewport as an [`AOI`](https://docs.descarteslabs.com/descarteslabs/geo/readme.html#descarteslabs.geo.AOI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d87a7-24a0-47a4-aee2-8dc811c05916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geocontext = m.geocontext()\n",
    "type(geocontext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ef896-7f89-4e38-8377-83e4b3302ded",
   "metadata": {},
   "source": [
    "Note these raster metadata attributes, which may vary depending on the provenance of the particular object:\n",
    "* __crs__: EPSG code\n",
    "* __bounds__: bounding rectangle of the viewport\n",
    "* __bounds_crs__: EPSG code\n",
    "* __shape__: shape of the resulting array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c034b10-6452-4e89-9cb1-80460c9a3ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geocontext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0198d6-a21f-4fc5-8710-fbfb8ff8ed70",
   "metadata": {},
   "source": [
    "### Putting the _Compute_ in Dynamic Compute\n",
    "Once we have _either_ a Mosaic or ImageStack _and_ a properly defined AOI we can now retrieve our pixel data as a numpy array.\n",
    "\n",
    "To do this we simply choose which bands we want to pull down and call either [`ImageStack.compute(aoi)`](https://docs.descarteslabs.com/api/dynamic-compute.html#descarteslabs.dynamic_compute.ImageStack.compute) or [`Mosaic.compute(aoi)`](https://docs.descarteslabs.com/api/dynamic-compute.html#descarteslabs.dynamic_compute.Mosaic.compute).\n",
    "\n",
    "Note that while resulting data type is a [`DotDict`](https://docs.descarteslabs.com/descarteslabs/utils/readme.html#descarteslabs.common.dotdict.dotdict.DotDict) we have _already retrieved the array we want_. \n",
    "* We can access that data by calling __.ndarray__ on our results dictionary. If we have __shape__ defined in our AOI that our resulting array's will be __(nbands, ny, nx)__\n",
    "* We also have properties returned to us in our results dictionary, which we will return to later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35534c-ee2c-4e49-a888-37f2d90759df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_mosaic_data = s2_mosaic.pick_bands(\"nir red green\").compute(geocontext)\n",
    "type(s2_mosaic_data)\n",
    "print(s2_mosaic_data.ndarray.shape)\n",
    "print(s2_mosaic_data.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d42b34-4769-4d87-9545-29ade016898d",
   "metadata": {},
   "source": [
    "And finally we can plot our dataset as an RGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2a0429-7213-427a-9cc3-3baca90df5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl.utils.display(s2_mosaic_data.ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746b966-f5ac-49a9-b56b-a9086961607b",
   "metadata": {},
   "source": [
    "We note there is some pesky cloud and cloud shadows present in our scene, but also recall that we have the _temporal dimension_ exposed to us through our ImageStack. We can also pull down that _entire stack of data_ through computing our ImageStack. \n",
    "\n",
    "Note the resulting array's shape here will instead be __(nsamples, nbands, ny, nx)__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3d11e-b14a-4599-94d4-ce4f709fd7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_stack_data = s2_stack.pick_bands(\"nir red green\").compute(geocontext)\n",
    "s2_stack_data.ndarray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4951e-a81c-464a-ae7c-070bfed0599d",
   "metadata": {},
   "source": [
    "Here we will return to our properties, where the metadata is much more useful than in our previous Mosaic example. \n",
    "\n",
    "We can retrieve each image's date through inline list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b12da-9dac-4686-b55e-5635e6f25f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "props = s2_stack_data.properties\n",
    "dates = [p[\"acquired\"].strftime(\"%Y-%m-%d %HH-%MM-%SS\") for p in props]\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5539ce-dee7-444f-b070-e9aa6d56fc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = [p[\"id\"] for p in props]\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df98d0-7e63-4b80-864d-faddad050793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titles = [f\"{ids[i]} \\n {dates[i]}\" for i in range(len(dates))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb26196-8d18-46c0-8e5b-d1ed804af5b9",
   "metadata": {},
   "source": [
    "### Pulling it All Together - ImageStacks\n",
    "Note here that each Image we retrieved in this stack _may not completely cover our input AOI_, that is because we have found an area _on the boundary between Sentinel-2 Imagery collections_. In the below plot we label each image with it's associated collectoin time as well as it's unique Image ID:\n",
    "\n",
    "Note here that not each indvidual image covers the entire input AOI, this is because we are plotting individual Sentinel-2 scenes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587257a-ee2f-458e-bc18-48602b84c43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl.utils.display(*s2_stack_data.ndarray, title=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cabe3d-79c7-449a-b669-8eb275b946f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1cf94-9cca-439a-92a0-66229278f75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
