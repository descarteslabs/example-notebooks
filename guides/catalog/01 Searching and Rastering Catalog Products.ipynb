{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd921a49-eb62-4775-9fb8-69bb2861d9dc",
   "metadata": {},
   "source": [
    "# Searching the Catalog\n",
    "All objects support the same search interface. `Searches` work by creating a query builder (class `Search`), which can be used in a fluent programming style to refine the search prior to execution by applying filtering, sorting, and limiting of result sets. Normally `Search` objects are created using class methods on one of the primary object types, e.g. `Product.search()`.\n",
    "\n",
    "The searches are then executed by any of several methods: calling the `count()` method to obtain a count of matching objects, using the `Search` object in an iterating context such as a for loop or a list comprehension to yield each matching object in turn, or calling the `collect()` method which will return a list-like collection object (e.g. `ProductCollection`, `BandCollection`, or `ImageCollection`).\n",
    "\n",
    "`Search` object methods never mutate the original object, but instead return modified copies. Thus Search objects can be reused for both further modification and repeated executions.\n",
    "\n",
    "Let’s look at two of the most commonly searched for types of objects: products and images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b467fbcb-1e3d-4f9e-ac57-e410b9e002fb",
   "metadata": {},
   "source": [
    "## Finding products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba67eb7c-36cd-4bff-b59e-436a9d17d2d2",
   "metadata": {},
   "source": [
    "### Filtering, sorting, and limiting\n",
    "Filtering is achieved through the use of the `Properties` class which allows you to express logical and comparison operations on attributes of an object such as a product or image. Multiple filters are combined as if by `AND`. Please see the API documentation for further details; the uses demonstrated below should be readily apparent. A general-use instance of this class can be imported from `descarteslabs.catalog.properties`.\n",
    "\n",
    "Sorting by an attribute of an object in either ascending or descending order is supported for many of the attributes of each object type.\n",
    "\n",
    "API documentation should be consulted to determine which properties support filtering and/or sorting. This is noted on each attribute’s specific documentation, e.g. `acquired`.\n",
    "\n",
    "Limiting allows you to restrict search results to at most a specified number of objects.\n",
    "\n",
    "`Product.search()` is the entry point for searching products. It returns a query builder that you can use to refine your search and can iterate over to retrieve search results.\n",
    "\n",
    "Count all products with some data before 2023 using `filter()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9b0cb-9c12-4c36-b4dc-f82e9941cff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from descarteslabs.catalog import Product, properties as p\n",
    "\n",
    "search = Product.search().filter(p.start_datetime < \"2023-01-01\")\n",
    "search.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da3bd7a-36de-4ac5-87c7-ce220964b18b",
   "metadata": {},
   "source": [
    "You can apply multiple filters. To restrict this search to products with data before 2023 and after 2000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c80c17-46c9-4f83-a584-6ffc8c6a8e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = search.filter(p.end_datetime > \"2000-01-01\")\n",
    "search.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6055762-3d23-4c0f-a330-18292e4e8e5b",
   "metadata": {},
   "source": [
    "All attributes are documented in the [Product API reference](https://docs.descarteslabs.com/descarteslabs/catalog/docs/product.html#descarteslabs.catalog.Product), which also spells out which ones can be used to filter or sort.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6161e85c-2ee2-4882-9bb1-ec9b644ab4a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Text search\n",
    "Add text search to the mix using `find_text()`. This finds all products with “landsat” in the name or description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583669be-3f88-427d-910b-1c3e97ab9284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "landsat_search = search.find_text(\"landsat\").limit(None)\n",
    "for product in landsat_search:\n",
    "    print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aab414-37a6-4dbc-abb6-2bb70c636d1d",
   "metadata": {},
   "source": [
    "### Lookup by id and object relationships\n",
    "If you know a product’s id, look it up directly with `Product.get()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd11fe-8d97-472a-9206-f359306d3862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "landsat8_collection1 = Product.get(\"usgs:landsat:oli-tirs:c2:l2:v0\")\n",
    "landsat8_collection1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e77674-d6c8-47e5-b97b-ab115c86b7d9",
   "metadata": {},
   "source": [
    "#### Bands\n",
    "Wherever there are relationships between objects expect methods such as `Product.bands()` to find related objects. This shows the first four bands of the Landsat 8 product we looked up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b363c4ad-6317-4bc9-bb4b-e1411b7c312d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for band in landsat8_collection1.bands().limit(5):\n",
    "    print(band)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c7999-2f53-466d-8ed0-8a80a9f3537f",
   "metadata": {},
   "source": [
    "In a similar fashion `Product.images()` returns a search object for images belonging to the product, as detailed in the next section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d448e8b-4670-46f8-974f-758c50d92f52",
   "metadata": {},
   "source": [
    "## Finding images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344c2517-c03b-4ff0-9de8-744b64fea9b6",
   "metadata": {},
   "source": [
    "### Image filters\n",
    "`Image` searches support a special method `intersects()` which is used to filter images by means of a geospatial search. Unlike `filter()` this method cannot be used multiple times. It will accept as an argument a GeoJSON dictionary, a shapely geometry, or any of the DL standard `GeoContext` object types. It will select any image for which the image geometry intersects the supplied geometry in lat-lon space (i.e. WGS84). As coordinate system transformations of bounding boxes are involved here, it should be noted that this filtering can be inexact; the overlap of geometries in the native coordinate system of the image may not be the same as that when transformed to the geographic coordinate system.\n",
    "\n",
    "Please see the `GeoContext Guide` for more information about working with `GeoContexts`.\n",
    "\n",
    "Please consult the API documentation for the `Image` class for information on which properties can be filtered.\n",
    "\n",
    "Search images by the most common attributes - by product, intersecting with a geometry and by a date range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbcabcc-c219-422a-9c5a-1174ae87e462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from descarteslabs.catalog import Image, Product, properties as p\n",
    "\n",
    "geometry = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [2.915496826171875, 42.044193618165224],\n",
    "            [2.838592529296875, 41.92475971933975],\n",
    "            [3.043212890625, 41.929868314485795],\n",
    "            [2.915496826171875, 42.044193618165224],\n",
    "        ]\n",
    "    ],\n",
    "}\n",
    "\n",
    "search = landsat8_collection1.images()\n",
    "search = search.intersects(geometry)\n",
    "search = search.filter(\"2023-01-01\" <= p.acquired < \"2023-06-01\")\n",
    "search = search.sort(\"acquired\")\n",
    "search.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4efd74-ef29-42e0-9088-ba1923689ac9",
   "metadata": {},
   "source": [
    "There are other attributes useful to filter by, documented in the API reference for [`Image`](https://docs.descarteslabs.com/descarteslabs/catalog/docs/image.html#descarteslabs.catalog.Image). For example exclude images with too much cloud cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe739ea-1f71-4c67-9bd9-d89ca4717960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search = search.filter(p.cloud_fraction < 0.2)\n",
    "search.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50405562-6a1a-464d-b98a-2502bdfc057e",
   "metadata": {},
   "source": [
    "Filtering by `cloud_fraction` is only reasonable when the product sets this attribute on images. `Images` that don’t set the attribute are excluded from the filter.\n",
    "\n",
    "The `created` timestamp is added to all objects in the catalog when they are created and is immutable. Restrict the search to results created before some time in the past, to make sure that the image results are stable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39053a14-5c29-4369-9d09-82e64e15c20b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "search = search.filter(p.created < datetime(2023, 4, 1))\n",
    "search.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa40aa-99ee-41aa-b7df-ffa9c801788e",
   "metadata": {},
   "source": [
    "Note that for all timestamps we can use `datetime` instances or strings that can reasonably be parsed as a timestamp. If a timestamp has no explicit timezone, it’s assumed to be in UTC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b16242-39de-4b4b-bb2c-652129f08466",
   "metadata": {},
   "source": [
    "## ImageCollections\n",
    "We can use the `collect()` method with an image search to obtain an `ImageCollection` with many useful features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bf477b-cd26-4a1d-977f-1c15bb17dd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = search.collect()\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a7af7-c33a-45b1-bdf6-6bf7e3dafe9f",
   "metadata": {},
   "source": [
    "Our original AOI for the search is available on the image collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ea1e8f-b0fc-40a1-936a-88e289a637b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images.geocontext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5521b6-9076-446f-899e-d2b69a3ae5b1",
   "metadata": {},
   "source": [
    "We can extract attributes across the collection with `each()`, or filter or group based on their attributes with `filter()` and `groupby()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f16d3-d87e-476f-bb36-2718f07d0bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(images.each.acquired.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fcbfe4-ef28-4896-8bcf-566ae5c24c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spring = images.filter(lambda i: 3 <= i.acquired.month < 6)\n",
    "list(spring.groupby(lambda i: i.acquired.month))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0ed62-fa62-4c9a-9d23-4afb9a3b64bd",
   "metadata": {},
   "source": [
    "## Rastering imagery\n",
    "`Image` and `ImageCollection` support a variety of methods that can be used to retrieve the image data associated with an image, including all manner of transformations such as coordinate systems, resolution, compositing, and scaling of pixel brightness. These operations can result in either a numpy ndarray of image data, or a GeoTIFF file on disk containing the image data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8d0340-36a2-439a-934f-5be88da7e601",
   "metadata": {},
   "source": [
    "### Rastering images\n",
    "To support the rastering of images, each image has a `geocontext` attribute which is a `GeoContext` instance describing the geospatial attributes of the image. All the rastering methods use this geocontext by default, but will accept another geocontext if desired. The resolution parameter can be used to change the resolution of the geocontext if desired.\n",
    "\n",
    "`Image` supports two methods for rastering, `ndarray()` and `download()`. A variety of parameters used to control the rastering are described in the documentation for those methods.\n",
    "\n",
    "With `ndarray()` the resulting data is returned as a 3-dimensional numpy array, with the first dimension representing the different bands selected (by default, this can be altered with the bands_axis parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9427c-4212-4148-9738-fda7e25d8071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from descarteslabs.catalog import Image\n",
    "from descarteslabs.utils import display\n",
    "\n",
    "image = Image.get(\n",
    "    \"usgs:landsat:oli-tirs:c2:l2:v0:LC08_L2SP_197031_20230106_20230110_02_T1\"\n",
    ")\n",
    "data = image.ndarray(\"red green blue\", resolution=120)\n",
    "(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a5c75-0ae1-46fa-bfc9-7ab192143c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(data, title=image.id, figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db04570-85fe-4b4b-bb05-ffb3eab89efc",
   "metadata": {},
   "source": [
    "The ordering of the axes within the ndarray are `(band, y, x)` or `(band, row, column)`.\n",
    "\n",
    "With `download()` the resulting data is stored in the local filesystem and the name of the file is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5155017-173a-470d-994b-08760dded002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from descarteslabs.catalog import Image\n",
    "\n",
    "image = Image.get(\n",
    "    \"usgs:landsat:oli-tirs:c2:l2:v0:LC08_L2SP_197031_20230106_20230110_02_T1\"\n",
    ")\n",
    "file = image.download(\"red green blue\", resolution=120)\n",
    "os.path.exists(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78669c08-c0da-44cd-809e-9afef01754ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542a54e-e99e-43c4-b6d4-a41b9c9fa01a",
   "metadata": {},
   "source": [
    "## Rastering image collections\n",
    "`ImageCollection` supports several methods for rastering. A variety of parameters used to control the rastering are described in the documentation for ech of these methods.\n",
    "\n",
    "`stack()` can be used to raster each of the images in the collection and then stack the resulting 3D arrays into a single 4-dimensional array, with the different images along the first axis in the order they appear in the ImageCollection (i.e. the axes are (image, band, y, x)). Note that rastering the images is performed in parallel, so this is significantly faster than rastering each image in the collection in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9af3ef-c075-403c-8465-43bedac64bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from descarteslabs.catalog import Product, properties as p\n",
    "\n",
    "geometry = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [2.915496826171875, 42.044193618165224],\n",
    "            [2.838592529296875, 41.92475971933975],\n",
    "            [3.043212890625, 41.929868314485795],\n",
    "            [2.915496826171875, 42.044193618165224],\n",
    "        ]\n",
    "    ],\n",
    "}\n",
    "\n",
    "search = landsat8_collection1.images()\n",
    "search = search.intersects(geometry).filter(\"2021-01-01\" <= p.acquired < \"2022-01-01\")\n",
    "search = search.filter(p.cloud_fraction <= 0.2)\n",
    "search = search.sort(\"acquired\")\n",
    "images = search.collect()\n",
    "data = images.stack(\"red green blue\", resolution=120)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9188a7e3-b0ad-45c2-a889-9d2b5cf91d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the first few\n",
    "display(*data[0:4], title=list(images[0:4].each.name), ncols=2, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5044be57-34ca-46b3-903a-80d562b8a5fc",
   "metadata": {},
   "source": [
    "`mosaic(`) can be used to composite the images to form a single image, resulting in a 3D array. A mosaic composite uses, for each pixel location, the pixel value from the last image in the collection containing a valid (unmasked) pixel value at that location. Since individual images may not cover the same pixels this operation is typically used to combine overlapping images to obtain a single complete image. If the image collection is sorted by increasing acquisition date, this means the most recent image wins. You can use the `sort()` method on the search object to alter the ordering of the images in the collection, or the `sort()` method on the ImageCollection itself to alter the ordering of the images and hence the results of the mosaic operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c0a72b-3049-4fe2-a150-0ae264adcada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = images.mosaic(\"red green blue\", resolution=120)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684e535-1438-4172-a946-4a0fdbbf1b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(data, title=\"Mosaic\", figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9496663e-674f-42e4-99fa-f240a54761ba",
   "metadata": {},
   "source": [
    "See the [Compositing Imagery with Catalog](https://docs.descarteslabs.com/examples-gallery/plot_images_mosaic.html) example for a more in-depth discussion of compositing by mosaic. Other kinds of compositing are possible but are not directly supported in the rastering engine but are easily achieved using the NumPy package, see the Composite Multi-Product Imagery example for the use of a median composite.\n",
    "\n",
    "Stacking and compositing can be combined using the `stack()` method with the flatten parameter. This uses the `groupby()` method to form a partitioning of the image list into multiple image lists of 1 or more images. Each sub-list is rastered as a composite (mosaic), and the multiple resulting mosaics are stacked. Note in this case that the first dimension of the resulting 4D array is equal to the number of different groups resulting from the flatten operation, and not the number of images in the original ImageCollection.\n",
    "\n",
    "In this example, we will group the images by the acquisition month. As there is at least one image each month, we end up with twelve partitioned image lists. Thus the resulting stack ends up with twelve mosaics. Note that the flatten operation preserves the original ordering of images within each group, so that if the original image collection is sorted by increasing acquired date, each mosaic will again represent “most recent image wins”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d984a37-db64-4aef-b2c6-84375c5dc632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for month, sublist in images.groupby(lambda i: i.acquired.month):\n",
    "    print(f\"Month {month:02} Images {sublist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f301a7-a9b3-478b-99a3-01485eb46f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = images.stack(\n",
    "    \"red green blue\", resolution=120, flatten=lambda i: i.acquired.month\n",
    ")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb8638-af36-40a2-ad3e-5bb324e1ce3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(*data, title=[f\"{m+1:02d}/2021\" for m in range(data.shape[0])], ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4497aaa-8cb0-4ebf-a07b-3f546db5e09a",
   "metadata": {},
   "source": [
    "in the image collection (but all using the same geocontext), while the `download_mosaic()` method composites the images in the ImageCollection just like the `mosaic()` method but results in a single geotiff file rather than an ndarray. The names of the resulting files are generated by default but can also be set explicitly. See the [API documentation](https://docs.descarteslabs.com/descarteslabs/catalog/docs/image.html#descarteslabs.catalog.ImageCollection) for further information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2129596c-e707-4149-963f-0a317877cd2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Common Rastering parameters\n",
    "Many of the rastering methods accept a common set of parameters including `geocontext, resolution, processing_level, scaling, data_type` and `progress`. These parameters are treated consistently across the different methods, and merit some explanation and examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58dc735-c2f2-4b08-bd4f-3a9ee2591161",
   "metadata": {},
   "source": [
    "### `geocontext` and `resolution`\n",
    "`Image` and `ImageCollection` objects have a default geocontext associated with them. The `Image.geocontext` attribute represents the geometry of the image, while the `ImageCollection.geocontext` attribute represents the geocontext used in the search that generated the collection, if any. If the geocontext parameter to a rastering method is not specified, this corresponding geocontext of the image or collection will be used by default. The resolution parameter can be used to override the resolution of the geocontext (whether defaulted or explicitly provided)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f0fb7d-1f51-4943-b7f9-a9f09f5fccf3",
   "metadata": {},
   "source": [
    "### `processing_level`\n",
    "The `processing_level` parameter allows the selection of different processing levels (e.g. `toa_reflectance` or `surface_reflectance`) supported by a product and its bands. When specifying a non-default processing level, the resulting data will often have a different data type and scaling than the raw image data. You must consult the `processing_levels` attribute to determine what processing levels a band supports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00712d-8cc9-4ecb-a9bc-393eaea26e10",
   "metadata": {},
   "source": [
    "### scaling and data_type\n",
    "When band raster data is retrieved, it can be scaled and converted to a variety of data types as required by the user. When neither of these parameters are provided, the original band data (or the selected `processing_level`) is copied into the result without change, while the resulting data type is automatically selected based on the data types of the bands in order to hold all the data without loss of precision or range.\n",
    "\n",
    "However, the user may specify several different alternative treatments of the band data. One of four automated scaling modes can be specified which direct the operation to rescale the pixel values in each band according to either the range of data in the image or ranges defined in the band attributes and targeting an appropriate output data type.\n",
    "\n",
    "The raw mode is equivalent to no scaling: the data is preserved as is (after applying any `processing_level`), and the output data type is selected to hold all the band data without loss of precision or range."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
